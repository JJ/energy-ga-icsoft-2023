\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}
\title{Minimizing evolutionary algorithms energy consumption in the low-level language Zig}

\author{
  Juan J. Merelo-Guerv√≥s\inst{1}\orcidID{0000-0002-1385-9741}
}
\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada, Granada, Spain}


\maketitle

\begin{abstract}
Managing energy resources in scientific computing implies needing to be aware of a wide range of engineering techniques that, when applied, are able to minimize the energy footprint of experiments. In the case of evolutionary computation, we are talking about a specialized workload that includes generation of chromosomes and operations that change parts of them or access and operate on them to obtain a floating point number. In a low level language such as Zig, we will show how different choices will affect the energy consumption of an experiment.
\keywords{Green computing, metaheuristics, energy-aware computing, evolutionary algorithms, zig}
\end{abstract}

\section{Introduction and state of the art}
\label{sec:introduction}

One of the concerns in modern evolutionary computing is reducing the amount of energy spent in experiments, trying to make nature-inspired computing more nature-friendly \cite{fernandez2019}. This involves developing a methodology to measure energy spent, as well as identifying the EC operations that consume the most energy. In \cite{DBLP:conf/icsoft/GuervosGC23} we settled on a language and OS-independent set of tools, but also followed \cite{abdelhafez2019component} in choosing the set of operations under measure: mutation, crossover and a simple fitness evaluation, ONEMAX.

In \cite{DBLP:conf/icsoft/GuervosGC23} the main factor under study was the different interpreters used in a high-level language, JavaScript. In the case of low-level languages like {\sf zig}, a language that emphasizes safety and maintainability \cite{friesen2023designing}, there is a single compiler, but there are several choices to be made, even if the defaults should provide enough performance and energy efficiency. Yet, in general, developers, and even more so scientific developers, are unaware of the energy impact of their algorithm implementations \cite{7155416}, not to mention techniques available for their reduction \cite{longo2019reducing}.

In this paper we will work on a generic evolutionary algorithm workload, and see what the impact of different choices will have on its energy consumption. With this, we will try to find some best practices that will help practitioners implement evolutionary algorithms in {\sf zig} or other low-level languages.

\section{Methodology and results}
\label{sec:res}

The experiment setup will match the one used in \cite{DBLP:conf/icsoft/GuervosGC23}, using the same tools for energy profiling ({\sf pinpoint}) as well as Perl scripts to run the experiments and process the results.
All experiments for this paper have been carried out in a Linux machine {\tt 5.15.0-94-generic \#104~20.04.1-Ubuntu SMP} using AMD Ryzen 9 3950X 16-Core Processor. These are the versions used for every tool and language, with {\sf zig}  version 0.11.0, released by August 3, 2023, which the last stable one at the time of writing this paper. The Perl scripts generate CSV files that are then processed and plotted using R embedded in the source code of this paper. All code, data and source for this paper are available at \url{https://github.com/JJ/energy-ga-icsoft2023} under a free license.

There are several units whose consumption can be measured using {\sf pinpoint} via the RAPL interface; since the use of GPU is negligible in these examples, only memory and CPUs will be measured. Together, they are called the {\em package} (alongside with caches and memory controllers); this is usually represented by the acronym {\sf PKG}.

We will be examining choices in three different areas\begin{itemize}
\item By default, {\sf zig} adds debug information to the resulting binary, without performing any kind of optimization. We will test the impact of using the {\sf ReleaseFast} option when building binaries.
\item The first version used strings for representing chromosomes. We will test instead arrays of Boolean values, which is  primitive type too.
\item Unlike other languages, {\sf zig} provides different memory allocators, which can be chosen by the developer. By default, a page allocator is used, but there is the possibility of using a fixed buffer size allocator.
\end{itemize}

We will first generate 40000 chromosomes of size 512, 1024 and 2048, and measure the energy consumption and running time of this operation; every combination is run 15 times. Not all combinations of the three techniques above could be tested, we show the results in Figure \ref{fig:lion.zig.setup}, along with the baseline that was compiled using default settings, character strings and page allocator. The other choices tested are: Built with {\sf ReleaseFast} option (tagged "ReleaseFast"), built in the same way and using a Fixed Buffer Allocator ("ReleaseFastFBA"), built with default options, using Boolean arrays as well as the Fixed Buffer Allocator ("Bool")\footnote{This combination proved difficult in practice, crashing the program for size 2048; it did not work with the {\sf ReleaseFast} option either}.

<<lion.zig.setup, echo=F, message=F, fig.pos="h!tb", fig.height=3, fig.cap="Average running time and PKG energy consumption generating 40K chromosomes for the different techniques used (represented with different colors); dot shape represents the chromosome size.">>=
library(dplyr)
library(ggplot2)

generate.chromosomes.zig <- read.csv("../data/lion-zig-gen-23-Feb-12-03-41.csv")
generate.chromosomes.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.zig.avg
generate.chromosomes.zig$size <- as.factor(generate.chromosomes.zig$size)

generate.chromosomes.fast <- read.csv("../data/lion-zig-gen-release-fast-6-Mar-09-35-05.csv")
generate.chromosomes.fast %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.fast.avg
generate.chromosomes.fast$size <- as.factor(generate.chromosomes.fast$size)

generate.chromosomes.bool <- read.csv("../data/lion-zig-gen-bool-7-Mar-08-44-39.csv")
generate.chromosomes.bool %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.bool.avg
generate.chromosomes.bool$size <- as.factor(generate.chromosomes.bool$size)

generate.chromosomes.fast.fba <- read.csv("../data/lion-zig-gen-release-fast-fba-6-Mar-09-53-10.csv")
generate.chromosomes.fast.fba %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.fast.fba.avg
generate.chromosomes.fast.fba$size <- as.factor(generate.chromosomes.fast.fba$size)

ggplot(generate.chromosomes.zig, aes(x=seconds, y=PKG, color="Default", shape=size)) +
  geom_point() +
  geom_point(data=generate.chromosomes.fast, aes(x=seconds, y=PKG, color="ReleaseFast", shape=size)) +
  geom_point(data=generate.chromosomes.bool, aes(x=seconds, y=PKG, color="Bool", shape=size)) +
  geom_point(data=generate.chromosomes.fast.fba, aes(x=seconds, y=PKG, color="ReleaseFastFBA", shape=size)) +
  scale_color_manual(values=c("black", "red", "blue", "green")) +
  labs(title="Running time and PKG energy consumption generating 40K chromosomes",
       x="Running time", y="PKG (Joules)") +
  theme_minimal()
@

This figure shows the dramatic change in energy consumption (as well as performance) that can be obtained just by changing compiling and programming options. Using a fixed buffer alongside the {\sf ReleaseFast} option implies a 95\% reduction in the energy consumed\footnote{We should take into account that generating chromosomes uses allocation heavily, so this is the kind of operation that would be the most impacted}. Even with the default compilation options, applying changes in the allocator and the data structure used reduces by 50\% energy used. The impact on running time, although not the focus of this paper, is also significant.

We will now run an experiment that, after generating the 40K chromosomes, will perform crossover + mutation + onemax operations on chromosomes of size 512, 1024 and 2048.

<<lion.combined.ops, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Running time and PKG energy consumption processing 40K chromosomes via crossover, mutation and ONEMAX for the three languages (represented with different colors); dot shape represents the chromosome size.">>=

combined.ops.zig <- read.csv("../data/lion-zig-ops-24-Feb-20-08-58.csv")
generate.zig.avgs.seconds <- c(rep( generate.chromosomes.zig.avg$mean.seconds[1], 15),
                               rep( generate.chromosomes.zig.avg$mean.seconds[2], 15),
                               rep( generate.chromosomes.zig.avg$mean.seconds[3], 15))
combined.ops.zig$diff.seconds <- combined.ops.zig$seconds - generate.zig.avgs.seconds
generate.zig.avgs.pkg <- c(rep( generate.chromosomes.zig.avg$mean.pkg[1], 15),
                            rep( generate.chromosomes.zig.avg$mean.pkg[2], 15),
                            rep( generate.chromosomes.zig.avg$mean.pkg[3], 15))
combined.ops.zig$diff.PKG <- combined.ops.zig$PKG - generate.zig.avgs.pkg
combined.ops.zig$size <- as.factor(combined.ops.zig$size)
combined.ops.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( diff.PKG ), sd.pkg = sd( diff.PKG), mean.seconds = mean( diff.seconds ) ) -> combined.ops.zig.avg

combined.ops.kotlin <- read.csv("../data/lion-kt-ops-25-Feb-13-34-30.csv")
generate.kotlin.avgs.seconds <- c(rep( generate.chromosomes.kotlin.avg$mean.seconds[1], 15),
                               rep( generate.chromosomes.kotlin.avg$mean.seconds[2], 15),
                               rep( generate.chromosomes.kotlin.avg$mean.seconds[3], 15))
combined.ops.kotlin$diff.seconds <- combined.ops.kotlin$seconds - generate.kotlin.avgs.seconds
generate.kotlin.avgs.pkg <- c(rep( generate.chromosomes.kotlin.avg$mean.pkg[1], 15),
                            rep( generate.chromosomes.kotlin.avg$mean.pkg[2], 15),
                            rep( generate.chromosomes.kotlin.avg$mean.pkg[3], 15))
combined.ops.kotlin$diff.PKG <- combined.ops.kotlin$PKG - generate.kotlin.avgs.pkg
combined.ops.kotlin$size <- as.factor(combined.ops.kotlin$size)

combined.ops.kotlin %>% group_by( size ) %>% summarise( mean.pkg = mean( diff.PKG ), sd.pkg = sd(diff.PKG), mean.seconds = mean( diff.seconds ) ) -> combined.ops.kotlin.avg

ggplot(combined.ops.bun, aes(x=diff.seconds, y=diff.PKG, shape=size, color="bun")) +
  geom_point() +
  geom_point(data=combined.ops.zig, aes(x=diff.seconds, y=diff.PKG, shape=size, color="zig")) +
  geom_point(data=combined.ops.kotlin, aes(x=diff.seconds, y=diff.PKG, shape=size, color="kotlin"))
  
@

<<lion.combined.ops.joules, echo=F, message=F>>=
library(kableExtra)


combined.ops.zig.avg$language <- "zig"
combined.ops.kotlin.avg$language <- "kotlin"

combined.ops <- rbind(combined.ops.bun.avg, combined.ops.zig.avg, combined.ops.kotlin.avg)
combined.ops$ops.joules <- 40000/ combined.ops$mean.pkg 
combined.ops$sd.ops.joules <- 40000/ combined.ops$sd.pkg
combined.ops %>% select( language, size, mean.pkg, sd.pkg, ops.joules ) %>% kable( digits = 2, col.names = c("Language","Size","PKG average","PKG SD", "Ops/Joule average"), caption = "Average operations per Joule in the combined operations experiment for the three languages." )
@


<<lion.hiff, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Running time and PKG energy consumption computing the HIFF fitness function for 40K chromosomes for the three languages (represented with different colors); dot shape represents the chromosome size.">>=

hiff.zig <- read.csv("../data/lion-zig-hiff-27-Feb-13-04-04.csv")
hiff.zig %>% mutate( delta.pkg = PKG - generate.chromosomes.zig.avg$mean.pkg[ match( size, generate.chromosomes.zig.avg$size ) ], delta.seconds = seconds - generate.chromosomes.zig.avg$mean.seconds[ match( size, generate.chromosomes.zig.avg$size ) ] ) -> hiff.zig.delta
hiff.zig.delta$size <- as.factor(hiff.zig.delta$size)

hiff.kotlin <- read.csv("../data/lion-kt-hiff-27-Feb-09-41-42.csv")
hiff.kotlin %>% mutate( delta.pkg = PKG - generate.chromosomes.kotlin.avg$mean.pkg[ match( size, generate.chromosomes.kotlin.avg$size ) ], delta.seconds = seconds - generate.chromosomes.kotlin.avg$mean.seconds[ match( size, generate.chromosomes.kotlin.avg$size ) ] ) -> hiff.kotlin.delta
hiff.kotlin.delta$size <- as.factor(hiff.kotlin.delta$size)

ggplot(hiff.bun.delta, aes(x=delta.seconds, y=delta.pkg, shape=size,color="bun")) +
  geom_point() + geom_point(data=hiff.zig.delta, aes(x=delta.seconds, y=delta.pkg, shape=size, color="zig")) + geom_point(data=hiff.kotlin.delta, aes(x=delta.seconds, y=delta.pkg, shape=size, color="kotlin")) +
  labs(title="HIFF", x="Seconds", y="PKG") +
  theme_minimal()

@


<<lion.hiff.boxplot, echo=F, message=F, warning=F, fig.pos="h!tb", fig.height=4, fig.cap="Boxplot of the energy consumption of the HIFF fitness function for 40K chromosomes for Kotlin and {\\protect\\sf zig}">>=
kotlin.zig.hiff <- data.frame(
  language = c(rep("kotlin",nrow(hiff.kotlin.delta)), rep("zig",nrow(hiff.zig.delta))),
  delta.pkg = c(hiff.kotlin.delta$delta.pkg, hiff.zig.delta$delta.pkg),
  size=as.factor(c(hiff.kotlin.delta$size, hiff.zig.delta$size)) 
  )
ggplot(kotlin.zig.hiff, aes(x=size, y=delta.pkg, fill=language)) + geom_boxplot() + labs(title="HIFF", x="Size", y="PKG") + theme_minimal()
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="512",])
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="1024",])
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="2048",])
@


<<lion.hiff.joules, echo=F, message=F>>=
library(kableExtra)
hiff.bun.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.bun.avg
hiff.zig.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.zig.avg
hiff.kotlin.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.kotlin.avg

hiff.bun.avg$language <- "bun"
hiff.zig.avg$language <- "zig"
hiff.kotlin.avg$language <- "kotlin"

hiff <- rbind(hiff.bun.avg, hiff.zig.avg, hiff.kotlin.avg)
hiff$ops.joules <- 40000/ hiff$mean.pkg 
hiff$sd.ops.joules <- 40000/ hiff$sd.pkg
hiff %>% select( language, size, mean.pkg, sd.pkg, ops.joules ) %>% kable( digits = 2, col.names = c("Language","Size","PKG average","PKG SD", "Ops/Joule average"), caption = "Average operations per Joule in the HIFF experiment for the three languages." )
@

What we see in Table \ref{tab:lion.hiff.joules} is the number of operations per Joule all three languages are able to perform.

\section{Discussion, conclusion and future work}
\label{sec:conclusions}


\section*{Acknowledgements and data availability}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR).

We are also very grateful to the {\sf zig} community, without which programming these operations in that language would have been impossible.

The source of this paper as well as the data and whole writing history is available from \url{https://github.com/JJ/energy-ga-icsoft-2023} under a GPL license.

\bibliographystyle{splncs04}

\bibliography{energy,javascript,geneura}


\end{document}

