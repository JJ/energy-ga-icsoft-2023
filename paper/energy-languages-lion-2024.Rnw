\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}

\title{How evolutionary algorithms consume energy depending on the language and its level}

\author{
  Juan J. Merelo-Guervós\inst{1}\orcidID{0000-0002-1385-9741}
and
  Mario García-Valdez\inst{2}\orcidID{0000-0002-2593-1114}
}
\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada, Granada, Spain \and
Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico\\
\email{jmerelo@ugr.es, mario@tectijuana.edu.mx}
}


\maketitle

\begin{abstract}
Making evolutionary algorithms greener imply tackling implementation issues from different angles. Practitioners need to focus on those that can be more easily leveraged, such as the choice of the language that is going to be used; high level (interpreted), mid-level (based on multi-platform virtual machines) and low-level (native) languages will need power in different ways, and choosing one or the other will have an impact on energy consumption. We will be looking at the implementation of key evolutionary algorithm functions, in three languages at three different levels: the high-level JavaScript, the mid-level Kotlin, which runs on the Java Virtual Machine, and the low level Zig. Looking beyond the obvious, as the lower the level, the less energy consumption should be expected, we will try to have a more holistic view of the implementation of the algorithms in order to  extract best practices regarding its green implementation.
\keywords{Green computing, metaheuristics, JavaScript, energy-aware computing, evolutionary algorithms, zig, Kotlin}
\end{abstract}

\section{\uppercase{Introduction}}
\label{sec:introduction}

The interest in greener computing has grown in the last decades, in part fueled by the Millenium Development Goals \cite{world2004millennium} that advocate for a lower carbon footprint in human activity, and in part due to the fact that performance improvements brought by faster hardware are not coming with the same speed as they used to \cite{theis2017end}.

We are, however, interested in evolutionary algorithms \cite{Corne_2018}, which, broadly speaking, fall within the field of artificial intelligence, and there are many different ways to lower the carbon footprint of computing workloads, however: as Hidalgo et al. affirm \cite{hidalgo2023sustainable}, there are four different levels for the evaluation and eventual improvement of energy consumption in AI (including, as in this paper, metaheuristics): just above the hardware level there is the programming language level, which includes not only the language itself, but also libraries and compilers or interpreters (inclusively named the {\em toolchain}. The latter were the topic of \cite{DBLP:conf/icsoft/GuervosGC23}, where our focus was to work on different JavaScript interpreters in order to discover which one used system energy more efficiently.

However, there are many user cases in which the language used by all or part of the metaheuristic implementation can also be chosen. A simple choice of language will impact greatly energy consumption, as shown in \cite{PEREIRA2021102609} or \cite{lima2016haskell}. In \cite{DBLP:conf/iwann/MereloRACML11} we looked at the performance of different languages when implementing an evolutionary algorithm; in this paper we will focus on the language level, before delving into specific language characteristics. Languages can be classified along many different axes: compiled vs. interpreted, low vs. high level, functional vs. procedural vs. object-oriented... In most cases, it is not a dichotomy, but a continuum; most interpreted languages, for instance, use Just-In-Time (JIT) compilers before actually running a script; most languages are also, nowadays, multi-paradigm, using procedural and functional as well as object-oriented features. Interpreted vs. compiled, low-level vs. high level are still useful distinctions, however, from the point of view of performance as well as what interests us most in this line of research, energy consumption.

Thus, for this paper, we will try to work with languages that occupy different positions along those two axes. We will work with a high level language, JavaScript, using the fastest implementation available, {\sf bun}; this is also an interpreted language, a high-level, compiled language, Kotlin, that compiles to bytecode of the Java virtual machine (JVM) and a low-level language, Zig, a relatively new language that is still not reached production, but is however used for {\sf bun} itself\footnote{Please note that there are no languages that are considered low-level and interpreted, although there are minimalistic interpreted languages like Lua \cite{ierusalimschy2007evolution}}. All these languages have toolchains that are free software, and thus can be used without any kind of limitation.

These languages can also be divided along two different axes that impact on their energy consumption:\begin{itemize}
\item Memory management: it is done automatically in high-level languages, like JavaScript and Kotlin, while it involves a series of choices in the case of Zig. Inasmuch as allocating and releasing memory consumes energy, there is going to be a difference between having a runtime or interpreter make heuristic choices, or the developers making that decision themselves.
\item Compilation: JavaScript is interpreted, Kotlin is compiled to bytecode and then interpreted by the JVM, and Zig is compiled to native code, but this implies also what happens with optimization: high-level languages take all decisions, while Zig will allow you to choose between different optimization levels; it also means that a different kind of overhead will be incurred when running a program: JavaScript will load the interpreter in memory, and then parse and run the program; Kotlin will actually use the Java virtual machine to run, and it will be loaded and then the bytecode parsed and run; finally, Zig creates executables, which will have some overhead due to standard linked libraries.
\end{itemize}

In general, this implies that although {\em a priori} we can assume that low-level language, being {\em closer to the iron}, will consume less resources, the fact that high-level languages apply heuristics and best practices to those decisions might eventually mean that, on the default case, the balance might be tipped towards high-level languages; this is going to be the main focus of this paper.

Making comparisons of energy spent by different implementations needs, first, a methodology to make choices that are comparable across all three platforms; then what exactly is going to be measured needs to be established, and how to make those measurements so that they make differences stand out. As in previous papers, we will focus on two critical evolutionary algorithm functions \cite{abdelhafez2019component}: the  fitness function, as well as {\em genetic} operators. However, we will use a heavier fitness function in this case: Hierarchical If and only IF (HIFF) \cite{watson1998modeling} for independent measurement, as well as combine mutation and crossover with OneMax. In general, we are going for combined, or more complex, operations in this paper, so that we can implicitly evaluate more features for every language, such as function calling or argument passing, which will have a different implementation, and thus energy overhead, in every language.

The rest of the paper is organized as follows: next we present the state of the art in software engineering and its analysis of energy consumption of different software platforms, to be followed by the methodology we are going to apply in this paper, mainly concerned with evolutionary algorithms in \ref{sec:meth}. Then we will present the results of the experiments in \ref{sec:results}, and finally we will discuss the results and draw some conclusions in \ref{sec:conclusions}.

\section{State of the art}
\label{sec:soa}

The shade of green of different languages has been repeatedly examined in the literature, at least since it actually became a concern in software engineering \cite{pinto2017energy}, very recently, indeed, this concern has been systematized in what are called the GREENER principles \cite{lannelongue2023greener}. These principles try to provide a foundation for Environmentally Sustainable Computer Science (ESCS), and are placed at different levels, from governance to Education. In this paper we are mainly concerned with the two Es, Estimation and Energy and embodied impact, as well as the R, research. These principles seek to monitor and then minimize the energy needs of computations; the Research principle, in turn, encourages to investigate on those topics. The GREENER principles try to kick-start a feedback loop that allows researches, and then developers in turn, to keep making decisions so that the same wallclock performance can be obtained with a minimal amount of energy.

We are interested on evolutionary algorithms, however, which have been studied from the point of view of energy consumption for some time \cite{10.1007/978-3-319-45823-6_51}; however it is interesting to note what these studies have focused in: population size \cite{diaz2022population}, hardware platform \cite{10.1007/978-3-319-45823-6_51}, the kind of algorithm \cite{garg2023analyzing} or the specific interpreter chosen to run the algorithm written in a specific language, JavaScript \cite{DBLP:conf/icsoft/GuervosGC23}. Although in this last case and in specific situation, energy savings of 90\% can be achieved, there are other possible choices that, in principle, might have a bigger impact without sacrificing performance (as would be the case when working with different hardware platforms).

And one of them



\section{Methodology}
\label{sec:meth}

In this paper we will factor out the time needed to generate the chromosomes; this is usually a one-shot in evolutionary algorithms and not very significant in evolutionary algorithm workloads, and it will allow us to focus on the added energy consumption of the operations themselves.

<<lion.setup, echo=F, message=F, fig.cap="Average running time and PKG energy consumption generating 40K chromosomes for the three languages (represented with different colors); dot size is proportional to the logarithm of the chromosome size">>=
library(dplyr)
library(ggplot2)
generate.chromosomes.bun <- read.csv("../data/generate-chromosomes-bun-lion-24.csv")
generate.chromosomes.bun  %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.bun.avg

generate.chromosomes.zig <- read.csv("../data/generate-chromosomes-zig-lion-24.csv")
generate.chromosomes.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.zig.avg

generate.chromosomes.kotlin <- read.csv("../data/generate-chromosomes-kotlin-lion-24.csv")
generate.chromosomes.kotlin %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.kotlin.avg

ggplot(generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun"))+ geom_point(data=generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun", size=log(size)))+geom_line(linewidth=1)+geom_point(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig", size=log(size)))+geom_line(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig"),linewidth=1)+geom_point(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin",size=log(size)))+geom_line(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin"), linewidth=1)
@


<<lion.hiff.bun, echo=F, message=F>>=

hiff.bun <- read.csv("../data/pinpoint-v3-HIFF-13-Dec-09-06-34.csv")
hiff.bun %>% mutate( delta.pkg = PKG - generate.chromosomes.bun.avg$mean.pkg[ match( size, generate.chromosomes.bun.avg$size ) ], delta.seconds = seconds - generate.chromosomes.bun.avg$mean.seconds[ match( size, generate.chromosomes.bun.avg$size ) ] ) -> hiff.bun.delta

generation.bun <- read.csv("../data/pinpoint-v3-generation-13-Dec-10-10-00.csv")
generation.bun %>% mutate( delta.pkg = PKG - generate.chromosomes.bun.avg$mean.pkg[ match( size, generate.chromosomes.bun.avg$size ) ], delta.seconds = seconds - generate.chromosomes.bun.avg$mean.seconds[ match( size, generate.chromosomes.bun.avg$size ) ] ) -> generation.bun.delta

@

\section{Results}
\label{sec:results}

\section{Discussion, conclusion and future work}
\label{sec:conclusions}

Implementing an algorithm implies making choices at different levels, from the type of language you will use to the specific language that meet your needs. Settling for languages at a certain level of abstraction will help you to stop your decisions at that level, and not have to carry them further, thus saving precious time in the life cycle of an experiment. % Conclude which languages are better


\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR).

\bibliographystyle{splncs04}

\bibliography{energy,javascript,geneura}


\end{document}

