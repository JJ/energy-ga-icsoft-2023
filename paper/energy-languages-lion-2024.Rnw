\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}
\title{How evolutionary algorithms consume energy depending on the language and its level}

\author{
  Juan J. Merelo-Guervós\inst{1}\orcidID{0000-0002-1385-9741}
and
  Mario García-Valdez\inst{2}\orcidID{0000-0002-2593-1114}
}
\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada, Granada, Spain \and
Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico\\
\email{jmerelo@ugr.es, mario@tectijuana.edu.mx}
}


\maketitle

\begin{abstract}
Making evolutionary algorithms greener implies tackling implementation issues from different angles. Practitioners need to focus on those that can be more easily leveraged, such as the choice of the language that is going to be used; high-level (interpreted), mid-level (based on multi-platform virtual machines), and low-level (native) languages will need power in different ways, and choosing one or the other will have an impact on energy consumption. We will be looking at the implementation of key evolutionary algorithm functions, in three languages at three different levels: the high-level JavaScript, the mid-level Kotlin, which runs on the Java Virtual Machine, and the low-level Zig. Looking beyond the obvious, as the lower the level, the less energy consumption should be expected, we will try to have a more holistic view of the implementation of the algorithms in order to  extract best practices regarding its green implementation.
\keywords{Green computing, metaheuristics, JavaScript, energy-aware computing, evolutionary algorithms, zig, Kotlin}
\end{abstract}

\section{\uppercase{Introduction}}
\label{sec:introduction}

The interest in greener computing has grown in the last decades, in part fueled by the Millennium Development Goals \cite{world2004millennium} that advocate for a lower carbon footprint in human activity and in part due to the fact that performance improvements brought by faster hardware are not coming with the same speed as they used to \cite{theis2017end}.

There are, however, no universal solutions, so we need to focus on specific field; the general field of artificial intelligence has received a lot of attention lately; we are, however, interested in evolutionary algorithms \cite{Corne_2018}, which, broadly speaking, fall within that field, but, unlike it, is not targeted by specific hardware processors relying on general CPU power (and its consumption). In the general sense, there are many different ways to lower the carbon footprint of computing workloads, however: as Hidalgo et al. affirm \cite{hidalgo2023sustainable}, there are four different levels for the evaluation and eventual improvement of energy consumption in AI (including, as in this paper, metaheuristics): just above the hardware level there is the programming language level, which includes not only the language itself, but also libraries and compilers or interpreters (inclusively named the {\em toolchain}. The latter was the topic of \cite{DBLP:conf/icsoft/GuervosGC23}, where our focus was to work on different JavaScript interpreters in order to discover which one used system energy more efficiently.

However, there are many user cases in which the language used by all or part of the metaheuristic implementation can also be chosen. A simple choice of language will greatly impact energy consumption, as shown in \cite{PEREIRA2021102609} or \cite{lima2016haskell}. In \cite{DBLP:conf/iwann/MereloRACML11}, we looked at the performance of different languages when implementing an evolutionary algorithm; in this paper, we will focus on the language level, before delving into specific language characteristics. Languages can be classified along many different axes: compiled vs. interpreted, low vs. high level, functional vs. procedural vs. object-oriented... In most cases, it is not a dichotomy, but a continuum; most interpreted languages, for instance, use Just-In-Time (JIT) compilers before actually running a script; most languages are also, nowadays, multi-paradigm, using procedural and functional as well as object-oriented features. Interpreted vs. compiled, low-level vs. high-level are still useful distinctions, however, from the point of view of performance as well as what interests us most in this line of research, energy consumption.

Thus, for this paper, we will try to work with languages that occupy different positions along those two axes. We will work with a high-level language, JavaScript, using the fastest implementation available, {\sf bun}; this is also an interpreted language, a high-level, compiled language, Kotlin, that compiles to bytecode of the Java virtual machine (JVM) and a low-level language, Zig, a relatively new language that is still not reached production, but is however used for {\sf bun} itself\footnote{Please note that there are no languages that are considered low-level and interpreted, although there are minimalist interpreted languages like Lua \cite{ierusalimschy2007evolution}}. All these languages have toolchains that are free software and thus can be used without any kind of limitation.

These languages can also be divided along two different axes that impact on their energy consumption:\begin{itemize}
\item Memory management: it is done automatically in high-level languages, like JavaScript and Kotlin, while it involves a series of choices in the case of Zig. Inasmuch as allocating and releasing memory consumes energy, there is going to be a difference between having a runtime or interpreter make heuristic choices, or the developers making those decisions themselves.
\item Compilation: JavaScript is interpreted, Kotlin is compiled to bytecode and then interpreted by the JVM, and Zig is compiled to native code, but this also implies what happens with optimization: high-level languages take all decisions, while Zig will allow you to choose between different optimization levels; it also means that a different kind of overhead will be incurred when running a program: JavaScript will load the interpreter in memory, and then parse and run the program; Kotlin will actually use the Java virtual machine to run, and it will be loaded and then the bytecode parsed and run; finally, Zig creates executables, which will have some overhead due to standard linked libraries.
\end{itemize}

In general, this implies that although {\em a priori}, we can assume that low-level language, being {\em closer to the iron}, will consume fewer resources, the fact that high-level languages apply heuristics and best practices to those decisions might eventually mean that, on the default case, the balance might be tipped towards high-level languages; this is going to be the main focus of this paper.

Making comparisons of energy spent by different implementations needs, first, a methodology to make choices that are comparable across all three platforms; then what exactly is going to be measured needs to be established, and how to make those measurements so that they make differences stand out. As in previous papers, we will focus on two critical evolutionary algorithm functions \cite{abdelhafez2019component}: the  fitness function, as well as {\em genetic} operators. However, we will use a heavier fitness function in this case: Hierarchical If and only IF (HIFF) \cite{watson1998modeling} for independent measurement, as well as combine mutation and crossover when solving the OneMax optimization problem. In general, we are going for combined, or more complex, operations in this paper so that we can implicitly evaluate more features for every language, such as function calling or argument passing, which will have a different implementation, and thus energy overhead, in every language.

The rest of the paper is organized as follows: next, we present the state of the art in software engineering and its analysis of energy consumption of different software platforms, to be followed by the methodology we are going to apply in this paper, mainly concerned with evolutionary algorithms in \ref{sec:meth}. Then we will present the results of the experiments in \ref{sec:results}, and finally, we will discuss the results and draw some conclusions in \ref{sec:conclusions}.

\section{State of the art}
\label{sec:soa}

The "shade of green" of different languages has been repeatedly examined in the literature, at least since it actually became a concern in software engineering \cite{pinto2017energy}, very recently, indeed.
This concern has been systematized in what are called the GREENER principles \cite{lannelongue2023greener}, which try to provide a foundation for Environmentally Sustainable Computer Science (ESCS), and are placed at different functional and pragmatic levels, from governance to education (that would be the last E). In this paper, we are mainly concerned with two other Es, estimation and "Energy and embodied impact," as well as the second R, Research. These principles seek to monitor and then minimize the energy needs of computations; the Research principle, in turn, encourages investigating those topics. We will call these principles EER, for short.
The GREENER principles try to kick-start a feedback loop that allows researchers, and then developers in turn, to keep making decisions so that the same wallclock performance can be obtained with a lesser amount of energy.

The enunciation of these principles is very recent; however, they have been applied to different areas, in different forms in the case of evolutionary algorithms, these have been studied for some time \cite{10.1007/978-3-319-45823-6_51} following the EER principles' point of view; however, it is interesting to note what these studies have focused in: population size \cite{diaz2022population}, hardware platform \cite{10.1007/978-3-319-45823-6_51}, the kind of algorithm \cite{garg2023analyzing} or the specific interpreter chosen to run the algorithm written in a specific language, JavaScript \cite{DBLP:conf/icsoft/GuervosGC23}. Although in this last case, in specific situations, energy savings of 90\% can be achieved, there are other possible choices that, in principle, might have a more significant impact without sacrificing performance (as would be the case when working with different hardware platforms).

And one of the ways of applying these EER principles is researching the programming language where we are going to implement the workload itself. A comprehensive and recent study \cite{PEREIRA2021102609}, that measures energy consumption on a general workload (the so-called CLBG corpus) shows that low-level languages like C, Rust or C++ are consistently coming on top.  Mid-level languages like Java are placed 5th on the overall energy ranking, with almost double energy consumption. Interpreted languages like JavaScript (probably using the mainstream interpreter, node.js) are placed 17th, spending energy at four times the rate of C. The last language in the ranking, Perl, spends two orders of magnitude more than the baseline; Python is next to last, with a less significant difference. Choosing the right platform is not everything, however, \cite{lima2016haskell} shows that the same algorithm implemented using different data structures might yield different levels of consumption; a similar problem is approached in \cite{connolly2023energy}, that shows that using the visitor pattern has a big impact in the energy profile of any program; however, the achieved reductions are very different depending on the language: while there is a slight reduction in the case of Java, the reduction achieved is dramatic in the case of C++. This probably shows that when we are comparing platforms we need to include the evaluation of higher-level components, that is, we need to go beyond the analysis of single functions.

In this paper, however, we will focus on the choice of programming languages based on how much energy they consume when applying the main operators of evolutionary algorithms. We also consider the role of higher-level language elements in its energy consumption. How we will be doing this work is presented next.

\section{Methodology}
\label{sec:meth}

An energy profiling methodology will start with selecting a tool to perform measurements, then present the workload that is going to be used, proceed to the different systems that are going to be measured, and end with the specific versions of the instruments and systems to be used; after this, the circumstances under which the measurement is going to take place need to be presented.

The measuring instrument was already chosen in a previous paper \cite{DBLP:conf/icsoft/GuervosGC23}. In general, there are system-wide as well as per-process measuring tools. We settled for {\sf pinpoint} \cite{9307947}, a command line tool under active development that takes per-process measures that are more accurate than other system-wide tools; it is also able to work with different sensor APIs across different operating systems, giving us an uniform tool to measure energy consumption.

In that paper, we selected a single integer arithmetic fitness function, MAXONES, and the crossover operation. However, in this paper we are taking a wider view of the problem so we will try to work with fundamental building blocks, but with ones that involve a bigger range of runtime system of the language. We will thus use two functions:\begin{itemize}
\item The Hierarchical If and only IF (HIFF) \cite{watson1998modeling} is an integer arithmetic function that works recursively, reducing a Boolean string of 0 and 1s by splitting it and applying the function to the halves; the final result will depend on the organization of 0s and 1s in the initial string, but will anyway involve many recursive function calls that will have to make use of the heap.
\item The other function will apply crossover to randomly selected pairs of binary strings, followed by mutation to every member of the resulting pair, and evaluate the ONEMAX function on that result. These are essentially five function calls, not as complicated as before, but it is a fundamental operation in evolutionary algorithms and will essentially test the ability to access random elements in a string, as well as the creation of new ones (or the cloning of them, depending on the implementation)
\end{itemize}

We will use a workload of the same size as in the previous paper, 40K chromosomes, with chromosomes of different sizes: 512, 1024, and 2048 bits. This is a difference with respect to the previous paper, where we did not use 512 bits, using 4096 instead. We consider that the bigger size is not as realistic, and is relatively unlikely to be found in real problems; besides, the amount of time needed to compute HIFF was really high for the high-level JavaScript, so we decided to drop it so that experiments can take place in a relatively reasonable amount of time.

The languages have been chosen using a specific criterion: \begin{itemize}
\item JavaScript is, as shown in the state of the art, one of the languages that consume the least energy as proved in \cite{PEREIRA2021102609}; in our previous paper, we have also found that using the {\sf bun} interpreter can results in savings as high as 90\% \cite{DBLP:conf/icsoft/GuervosGC23}. It is a high-level, object-oriented language that is, indeed, quite popular. It has been preferred over other languages that might have a higher popularity in metaheuristics, such as Python, since the above-mentioned paper includes it as one of the languages that consume the most energy in a general payload; metaheuristics need not be an exception. At any rate, this paper is about choosing among kinds of languages, so any result that is obtained might be extended to languages of the same kind; at the same kind, we propose a methodology for choosing the right system for metaheuristics, so more precise measurements would have to be performed on whatever alternative to JavaScript we want to introduce. The implementation of the above-mentioned function is open source and hosted at \url{https://github.com/JJ/energy-ga-icsoft2023} with a free license. The actual code is the same used in the above mentioned paper.
\item Kotlin is a language that compiles to the JVM, and in that sense, it would be comparable to Java in terms of energy consumption. However, data structures and other runtime characteristics might differ, as well as the workload, so what we obtain in terms of ranking might be different from what \cite{PEREIRA2021102609} shows. As we mentioned above, and on a first approximation, results obtained here might be extended to other languages such as Java, Scala, or Clojure that also target the JVM. Kotlin has not been the target of any popular EA library as far as we can tell, although it is mentioned in this context in works such as \cite{hollo2021statistical}. The implementation that has been used is also included in the same repository and has been adapted from the one used in \cite{merelo2016ranking,merelo2017ranking}. In that study, Kotlin was one of the fastest, even faster than Java in one of the versions.
\item Finally, we use Zig as the low-level language instead of the more popular in EA circles C++, or, in general terms, Rust. We chose it mainly because the interpreter we use for JS is written using it; so we should expect less energy consumption when we lower the level of abstraction. On the other hand, it would be a totally new implementation of evolutionary algorithms, so this work could serve to introduce the language (and its possibilities) to practitioners. Again, the implementation is hosted in the same repository as the others used for this paper.
\end{itemize}

All experiments for this paper have been carried out in a Linux machine {\tt 5.15.0-94-generic \#104~20.04.1-Ubuntu SMP} using AMD Ryzen 9 3950X 16-Core Processor. These are the versions used for every tool and language:\begin{itemize}
\item {\sf pinpoint} does not have a version, but it has been compiled from commit {\tt 1578db07b1ee30318966d7a2097ee1bb219a9dc8}, October 26 2023.
\item {\sf bun} uses version 1.0.7.\footnote{Please note that at the time of writing this, many other versions have been published; we have used this one to be able to compare with previous papers. These same papers show that its performance and energy consumption have important improvements, so in case of close calls, we would recommend retaking measurements at the time of running your experiments}
\item {\sf zig} uses version 0.11.0. This version, released by August 3, 2023, is the last one at the time of writing this paper.
\item Kotlin version string is {\tt 1.9.22-release-704}; this includes the JVM version, OpenJDK 11.0.21.
\end{itemize}

All programs are run through a Perl script that captures and processes output, generating CSV data files that are committed to this repository, and available under a free license. Instructions to compile and run it are also included in the repository; in general, all that is needed to reproduce the results of this paper. All the code is automatically tested and tagged so that the exact version used in this paper can be retrieved.

Implementing an algorithm will always imply some choices in the specifics used to program it. In general, we opted for the default implementation (as suggested by tutorials), but explicitly, these are the decisions we took:\begin{itemize}
\item {\sf bun} uses the same implementation as previously used, namely, mutable strings, to represent the chromosome.
\item {\sf zig}, being a low-level language, needs a bigger set of choices. We have used {\tt DefaultPrng} as random number generator, {\tt page\_allocator} as allocator, and arrays of byte-size integers ({\tt u8}) for the chromosomes. This is the default implementation of integers in the language. The executable has been generated with default options too ({\tt optimize} for optimization).
\item {\sf Kotlin} uses again the same implementation as \cite{merelo2016ranking}, a {\tt BooleanArray} for every chromosome.
\end{itemize}

All results shown below are averages for 15 runs for every configuration.

Please note that no sort of energy-wise optimizations have been performed on these implementations, since the main users of this work would be students and scientists with no deep knowledge of specific programming languages who want to create energy-efficient implementations of their algorithms. Every one of the languages has different levers that could be used to optimize energy, but that is not the focus of this paper. At any rate, if there is a close call in the results, the reader should take it into account and again measure energy consumption for specific workloads.

Previously, the experiment runner eliminated the baseline energy consumption by subtracting the average consumption of an idle process during the average time the experiments took; however, that implied that the energy (and time) measured included {\em generation} of the chromosomes, as well as the operations themselves.

In this paper, we will factor out that time, as well as the energy spent. Since generating chromosomes is made just once at the beginning of the run in evolutionary algorithms and is thus not very significant in evolutionary algorithm workloads, subtracting it from the experiment run time will allow us to focus on the added energy consumption of the operations themselves; the results published in the next section will then subtract the average time and energy consumption of this operation, which is shown in Figure \ref{fig:lion.setup}.

<<lion.setup, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Average running time and PKG energy consumption generating 40K chromosomes for the three languages (represented with different colors); dot size is proportional to the logarithm of the chromosome size.">>=
library(dplyr)
library(ggplot2)
generate.chromosomes.bun <- read.csv("../data/generate-chromosomes-bun-lion-24.csv")
generate.chromosomes.bun  %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.bun.avg

generate.chromosomes.zig <- read.csv("../data/lion-zig-gen-23-Feb-12-03-41.csv")
generate.chromosomes.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.zig.avg

generate.chromosomes.kotlin <- read.csv("../data/generate-chromosomes-kotlin-lion-24.csv")
generate.chromosomes.kotlin %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.kotlin.avg

ggplot(generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun"))+ geom_point(data=generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun", size=log(size)))+geom_line(linewidth=1)+geom_point(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig", size=log(size)))+geom_line(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig"),linewidth=1)+geom_point(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin",size=log(size)))+geom_line(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin"), linewidth=1)
@

This Figure  \ref{fig:lion.setup} shows average energy consumed ({\tt mean.pkg}) vs. time taken ({\tt mean.seconds}), already allows us at least an initial comparison of the orders of magnitude of the difference we should expect. Clearly, Kotlin is the fastest and also the one that consumes the least energy; it is followed by {\sf zig}, although time as well as energy consumption grow very fast with the size of the chromosomes (here represented logarithmically as the dot size). {\sf bun} is the slowest, as well as the one that consumes the most energy, although we should note that for the bigger size (2048 bits) {\sf zig} takes almost the same amount of time, although with a lower consumption of energy\footnote{{\sf zig} will greatly vary the amount of energy needed depending on relatively irrelevant choices such as using constant or mutable pointers; in a previous experiment run, included in the repository, that used mutable pointers, energy consumption was almost 10\% higher.}.

We will proceed to the experiments on an evolutionary algorithm workload, which will use this as a baseline.

\section{Results}
\label{sec:results}

The first experiment will perform 40K crossover + mutation + onemax operations on chromosomes of size 512, 1024 and 2048.

<<lion.combined.ops, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Running time and PKG energy consumption processing 40K chromosomes via crossover, mutation and ONEMAX for the three languages (represented with different colors); dot shape represents the chromosome size.">>=

combined.ops.bun <- read.csv("../data/lion-bun-22-Feb-13-55-23.csv")
generate.bun.avgs.seconds <- c(rep( generate.chromosomes.bun.avg$mean.seconds[1], 15),
                               rep( generate.chromosomes.bun.avg$mean.seconds[2], 15),
                               rep( generate.chromosomes.bun.avg$mean.seconds[3], 15))
combined.ops.bun$diff.seconds <- combined.ops.bun$seconds - generate.bun.avgs.seconds
generate.bun.avgs.pkg <- c(rep( generate.chromosomes.bun.avg$mean.pkg[1], 15),
                            rep( generate.chromosomes.bun.avg$mean.pkg[2], 15),
                            rep( generate.chromosomes.bun.avg$mean.pkg[3], 15))
combined.ops.bun$diff.PKG <- combined.ops.bun$PKG - generate.bun.avgs.pkg
combined.ops.bun$size <- as.factor(combined.ops.bun$size)

combined.ops.bun  %>% group_by( size ) %>% summarise( mean.pkg = mean( diff.PKG ), sd.pkg = sd(diff.PKG), mean.seconds = mean( diff.seconds ) ) -> combined.ops.bun.avg

combined.ops.zig <- read.csv("../data/lion-zig-ops-24-Feb-20-08-58.csv")
generate.zig.avgs.seconds <- c(rep( generate.chromosomes.zig.avg$mean.seconds[1], 15),
                               rep( generate.chromosomes.zig.avg$mean.seconds[2], 15),
                               rep( generate.chromosomes.zig.avg$mean.seconds[3], 15))
combined.ops.zig$diff.seconds <- combined.ops.zig$seconds - generate.zig.avgs.seconds
generate.zig.avgs.pkg <- c(rep( generate.chromosomes.zig.avg$mean.pkg[1], 15),
                            rep( generate.chromosomes.zig.avg$mean.pkg[2], 15),
                            rep( generate.chromosomes.zig.avg$mean.pkg[3], 15))
combined.ops.zig$diff.PKG <- combined.ops.zig$PKG - generate.zig.avgs.pkg
combined.ops.zig$size <- as.factor(combined.ops.zig$size)
combined.ops.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( diff.PKG ), sd.pkg = sd( diff.PKG), mean.seconds = mean( diff.seconds ) ) -> combined.ops.zig.avg

combined.ops.kotlin <- read.csv("../data/lion-kt-ops-25-Feb-13-34-30.csv")
generate.kotlin.avgs.seconds <- c(rep( generate.chromosomes.kotlin.avg$mean.seconds[1], 15),
                               rep( generate.chromosomes.kotlin.avg$mean.seconds[2], 15),
                               rep( generate.chromosomes.kotlin.avg$mean.seconds[3], 15))
combined.ops.kotlin$diff.seconds <- combined.ops.kotlin$seconds - generate.kotlin.avgs.seconds
generate.kotlin.avgs.pkg <- c(rep( generate.chromosomes.kotlin.avg$mean.pkg[1], 15),
                            rep( generate.chromosomes.kotlin.avg$mean.pkg[2], 15),
                            rep( generate.chromosomes.kotlin.avg$mean.pkg[3], 15))
combined.ops.kotlin$diff.PKG <- combined.ops.kotlin$PKG - generate.kotlin.avgs.pkg
combined.ops.kotlin$size <- as.factor(combined.ops.kotlin$size)

combined.ops.kotlin %>% group_by( size ) %>% summarise( mean.pkg = mean( diff.PKG ), sd.pkg = sd(diff.PKG), mean.seconds = mean( diff.seconds ) ) -> combined.ops.kotlin.avg

ggplot(combined.ops.bun, aes(x=diff.seconds, y=diff.PKG, shape=size, color="bun")) +
  geom_point() +
  geom_point(data=combined.ops.zig, aes(x=diff.seconds, y=diff.PKG, shape=size, color="zig")) +
  geom_point(data=combined.ops.kotlin, aes(x=diff.seconds, y=diff.PKG, shape=size, color="kotlin"))
  
@

Figure \ref{fig:lion.combined.ops}, shows the difference in running time and PKG energy consumption for the three languages examined. We have opted to show the results for every experiment in a single plot, to reveal trends as well as some quirks that might be explained more by language idiosyncrasies than by experimental errors. For instance, we can see that there are several cases where the Kotlin experimentation takes a long time, even for 1024 bits and 512 bits. One of the issues that the JVM has is garbage recollection; if there is a garbage recollection cycle it can clearly impact performance. The fact that it has hit a percentage of the experiments reveals that specific behaviors need to be taken into account and, to the extent that it is possible, mitigated.

Another quirk is the lower-than-0 energy consumption for {\sf zig}, simply revealing that the difference in energy consumption is so low that it falls below the average for the generation of the chromosomes. {\sf zig}'s energy consumption is never higher than 60 Joules, anyway.

The trends need to be pondered, too. In general, {\sf bun} is going to take longer and consume more energy than the rest for every size; Kotlin is the fastest and boasts the lower consumption of energy overall for smaller sizes. {\sf zig}, on the other hand, is faster than {\sf bun}, and its speed is quite consistent; not so for consumption of energy, which can go from very low, to even less than Kotlin in some experiments (and virtually zero), to relatively high, with a maximum closer to the average for {\sf bun}.

<<lion.combined.ops.joules, echo=F, message=F>>=
library(kableExtra)

combined.ops.bun.avg$language <- "bun"
combined.ops.zig.avg$language <- "zig"
combined.ops.kotlin.avg$language <- "kotlin"

combined.ops <- rbind(combined.ops.bun.avg, combined.ops.zig.avg, combined.ops.kotlin.avg)
combined.ops$ops.joules <- 40000/ combined.ops$mean.pkg 
combined.ops$sd.ops.joules <- 40000/ combined.ops$sd.pkg
combined.ops %>% select( language, size, mean.pkg, sd.pkg, ops.joules ) %>% kable( digits = 2, col.names = c("Language","Size","PKG average","PKG SD", "Ops/Joule average"), caption = "Average operations per Joule in the combined operations experiment for the three languages." )
@

What we see in Table \ref{tab:lion.combined.ops.joules} is a complicated scenario, where Kotlin has a very high number of operations per Joule, with a power consumption as low as 12 Joules for the smallest size, although the trend is slightly different for the middle size of 1024 bits, where {\sf zig} obtains the lowest energy consumption and operations per Joule, mainly due to the fact that the standard deviation for Kotlin, probably due to garbage recollection operations, is very high. Remarkably, the energy consumption for Kotlin can be as low as 1/3 of what {\sf bun} requires; {\sf zig} requires half (although they can be very close for the smallest value, where Kotlin excels).

We need to check the speed and consumption of the selected fitness function, HIFF, for the three languages, so we can have a more complete picture of the energy profile for the three languages. This is a heavy-weight function, involving function calls in the order of one thousand. Even if it is going to take much more time than generating the chromosomes, we will still subtract the time needed for that operation to compare different things uniformly.

The operation for these functions needed some tweaking, namely, conversion to string in the case of Kotlin and to constant string in the case of {\sf zig}. This adds what is essentially a copying operation to the fitness itself, but we decided to do that in order to have HIFF defined in the most similar way possible (working with strings of 0s and 1s). 

<<lion.hiff, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Running time and PKG energy consumption computing the HIFF fitness function for 40K chromosomes for the three languages (represented with different colors); dot shape represents the chromosome size.">>=

hiff.bun <- read.csv("../data/pinpoint-v3-HIFF-13-Dec-09-06-34.csv")
hiff.bun %>% mutate( delta.pkg = PKG - generate.chromosomes.bun.avg$mean.pkg[ match( size, generate.chromosomes.bun.avg$size ) ], delta.seconds = seconds - generate.chromosomes.bun.avg$mean.seconds[ match( size, generate.chromosomes.bun.avg$size ) ] ) -> hiff.bun.delta
hiff.bun.delta$size <- as.factor(hiff.bun.delta$size)

hiff.zig <- read.csv("../data/lion-zig-hiff-27-Feb-13-04-04.csv")
hiff.zig %>% mutate( delta.pkg = PKG - generate.chromosomes.zig.avg$mean.pkg[ match( size, generate.chromosomes.zig.avg$size ) ], delta.seconds = seconds - generate.chromosomes.zig.avg$mean.seconds[ match( size, generate.chromosomes.zig.avg$size ) ] ) -> hiff.zig.delta
hiff.zig.delta$size <- as.factor(hiff.zig.delta$size)

hiff.kotlin <- read.csv("../data/lion-kt-hiff-27-Feb-09-41-42.csv")
hiff.kotlin %>% mutate( delta.pkg = PKG - generate.chromosomes.kotlin.avg$mean.pkg[ match( size, generate.chromosomes.kotlin.avg$size ) ], delta.seconds = seconds - generate.chromosomes.kotlin.avg$mean.seconds[ match( size, generate.chromosomes.kotlin.avg$size ) ] ) -> hiff.kotlin.delta
hiff.kotlin.delta$size <- as.factor(hiff.kotlin.delta$size)

ggplot(hiff.bun.delta, aes(x=delta.seconds, y=delta.pkg, shape=size,color="bun")) +
  geom_point() + geom_point(data=hiff.zig.delta, aes(x=delta.seconds, y=delta.pkg, shape=size, color="zig")) + geom_point(data=hiff.kotlin.delta, aes(x=delta.seconds, y=delta.pkg, shape=size, color="kotlin")) +
  labs(title="HIFF", x="Seconds", y="PKG") +
  theme_minimal()

@

The results for time and energy consumption are represented in Figure \ref{fig:lion.hiff}. We can already observe that the consumption is more than one order of magnitude higher than before, and since the number of function calls is dependent on the chromosome size, it grows more or less linearly with size. We can also observe that, as usual, {\sf bun} is the slowest and the one that consumes the most energy.

However, the situation with {\sf zig} and {\sf Kotlin} is different. {\sf Kotlin} is in most cases slightly slower, but also more energy-saving, thus more {\em green} than  {\sf zig}. We represent a boxplot comparing them in Figure \ref{fig:lion.hiff.boxplot}.

<<lion.hiff.boxplot, echo=F, message=F, warning=F, fig.pos="h!tb", fig.height=4, fig.cap="Boxplot of the energy consumption of the HIFF fitness function for 40K chromosomes for Kotlin and {\\protect\\sf zig}">>=
kotlin.zig.hiff <- data.frame(
  language = c(rep("kotlin",nrow(hiff.kotlin.delta)), rep("zig",nrow(hiff.zig.delta))),
  delta.pkg = c(hiff.kotlin.delta$delta.pkg, hiff.zig.delta$delta.pkg),
  size=as.factor(c(hiff.kotlin.delta$size, hiff.zig.delta$size)) 
  )
ggplot(kotlin.zig.hiff, aes(x=size, y=delta.pkg, fill=language)) + geom_boxplot() + labs(title="HIFF", x="Size", y="PKG") + theme_minimal()
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="512",])
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="1024",])
# wilcox.test(delta.pkg ~ language, data=kotlin.zig.hiff[kotlin.zig.hiff$size=="2048",])
@

Differences are significant for all three languages, for all sizes involved; in the case of the biggest size, there is indeed a considerable difference, with Kotlin spending less than 1500 Joules on average.

<<lion.hiff.joules, echo=F, message=F>>=
library(kableExtra)
hiff.bun.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.bun.avg
hiff.zig.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.zig.avg
hiff.kotlin.delta %>% group_by( size ) %>% summarise( mean.pkg = mean( delta.pkg ), sd.pkg = sd( delta.pkg), mean.seconds = mean( delta.seconds ) ) -> hiff.kotlin.avg

hiff.bun.avg$language <- "bun"
hiff.zig.avg$language <- "zig"
hiff.kotlin.avg$language <- "kotlin"

hiff <- rbind(hiff.bun.avg, hiff.zig.avg, hiff.kotlin.avg)
hiff$ops.joules <- 40000/ hiff$mean.pkg 
hiff$sd.ops.joules <- 40000/ hiff$sd.pkg
hiff %>% select( language, size, mean.pkg, sd.pkg, ops.joules ) %>% kable( digits = 2, col.names = c("Language","Size","PKG average","PKG SD", "Ops/Joule average"), caption = "Average operations per Joule in the HIFF experiment for the three languages." )
@

What we see in Table \ref{tab:lion.hiff.joules} is the number of operations per Joule all three languages are able to perform.

\section{Discussion, conclusion and future work}
\label{sec:conclusions}

In this paper, we have performed a series of experiments running an evolutionary algorithm workload using three different languages with different {\em levels} (different ways of running the --possibly compiled-- code), which translate to different ways of running the algorithms. Focusing on a set of operations allows us to create specific energy profiles for the algorithm implementations, as well as the languages. The methodology followed enables to benchmark the energy consumption of the different languages, as well as to differentiate them; it does not consume an excessive amount of time. Showing the results as operations per Joule focuses the the attention on how "green" every language is, by showing precisely how many operations can be performed with a certain amount of energy.

In this work, we compared the performance regarding power consumption of three languages, JavaScript (using the {\sf bun} high-performance interpreter), Kotlin (using a free JVM), and {\sf zig}, when implementing certain important operations in evolutionary algorithms. We have used two workloads, one with a combination of genetic operators and the OneMax fitness function (which would be a lightweight, although widely used, combination), and another with the HIFF fitness function, which is not only heavier in terms of operations, but also recursive, thus involving specific language overheads.

In all cases (that include also the generation of the chromosomes measured, used as baseline) we have found that the combination of Kotlin and the JVM is the most energy-efficient language (as well as the faster, although that was not the main focus of the experiment), followed by {\sf zig}, and finally JavaScript using {\sf bun} as interpreter. The difference is bigger for core-only operations, where Kotlin can be twice as fast as {\sf bun}, than in other operations that involve the overhead of function calls, like HIFF, where the difference is much smaller, around 5\% for {\sf zig} and Kotlin in the chromosomes with the biggest size. The fact that {\sf zig} can be slightly faster than Kotlin in this last case is not really relevant from the point of view of the energy efficiency; Kotlin still needs less energy even if it takes a bit longer; you can trade off easily energy efficiency for speed in this case, since the average difference is just a few percentage points.

The relatively small difference between Kotlin and {\sf zig} might imply that with some engineering and optimizations, {\sf zig} energy efficiency might be on a par with Kotlin. Low level languages have many different ways of optimizing its design and tooling, and we did not create the {\sf zig} program at an expert level. However, this level is consistent with the use case we are giving the application, those of a scientist acting as a developer, not an expert developer of system software (which is the most common use case for {\sf zig}). We cannot then affirm that Kotlin is the most efficient across the board, but we can definitely propose it as the {\em greener} technology for the specific case of evolutionary algorithms that do not have an extensive amount of GPU use; this would include mainly tests for new operators or, in general, new methodologies for evolutionary algorithms that use common fitness functions.

The interesting thing about modern experimental setup is that different languages can be easily mixed in a single application. As we can see in the experiments above, energy expenses of fitness functions can be twice as high as the rest of the operations; using {\em green} languages exclusively in this case, leaving the rest of the application to easier-to-use interpreted languages will not have a big impact in the energy profile, while simplifying the development as well as the integration within current frameworks such as DEAP \cite{fortin2012deap}. 

As future lines of work, we plan to extend this study to other languages and workloads, especially those that use different kind of virtual machines like Haskell or Elixir. On the algorithmic side, another research venue is to analyze the energy consumption of languages implementing different concurrency models, implemented either by language constructs or through specialized virtual machines. We also plan to analyze the energy consumption of different hardware platforms (including the cloud), and to develop a tool to help researchers and developers to choose the most energy-efficient language for their needs.

An investigation focused on {\sf zig} would also help understand how low-level languages can be made {\em greener} and to what extent energy efficiency can be improved.

\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR).

We are also very grateful to the {\sf zig} community, without which programming these operations in that language would have been impossible.

\section*{Data availability}

The source of this paper as well as the data and whole writing history is available from \url{https://github.com/JJ/energy-ga-icsoft-2023} under a GPL license.

\bibliographystyle{splncs04}

\bibliography{energy,javascript,geneura}


\end{document}

