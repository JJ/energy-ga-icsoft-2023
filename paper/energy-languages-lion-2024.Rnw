\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}

\title{How evolutionary algorithms consume energy depending on the language and its level}

\author{
  Juan J. Merelo-Guervós\inst{1}\orcidID{0000-0002-1385-9741}
and
  Mario García-Valdez\inst{2}\orcidID{0000-0002-2593-1114}
}
\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada, Granada, Spain \and
Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico\\
\email{jmerelo@ugr.es, mario@tectijuana.edu.mx}
}


\maketitle

\begin{abstract}
Making evolutionary algorithms greener implies tackling implementation issues from different angles. Practitioners need to focus on those that can be more easily leveraged, such as the choice of the language that is going to be used; high-level (interpreted), mid-level (based on multi-platform virtual machines), and low-level (native) languages will need power in different ways, and choosing one or the other will have an impact on energy consumption. We will be looking at the implementation of key evolutionary algorithm functions, in three languages at three different levels: the high-level JavaScript, the mid-level Kotlin, which runs on the Java Virtual Machine, and the low-level Zig. Looking beyond the obvious, as the lower the level, the less energy consumption should be expected, we will try to have a more holistic view of the implementation of the algorithms in order to  extract best practices regarding its green implementation.
\keywords{Green computing, metaheuristics, JavaScript, energy-aware computing, evolutionary algorithms, zig, Kotlin}
\end{abstract}

\section{\uppercase{Introduction}}
\label{sec:introduction}

The interest in greener computing has grown in the last decades, in part fueled by the Millenium Development Goals \cite{world2004millennium} that advocate for a lower carbon footprint in human activity and in part due to the fact that performance improvements brought by faster hardware are not coming with the same speed as they used to \cite{theis2017end}.

There are, however, no universal solutions, so we need to focus on specific field; the general field of artificial intelligence has received a lot of attention lately; we are, however, interested in evolutionary algorithms \cite{Corne_2018}, which, broadly speaking, fall within that field, but, unlike it, is not targeted by specific hardware processors relying on general CPU power (and its consumption). In the general sense, there are many different ways to lower the carbon footprint of computing workloads, however: as Hidalgo et al. affirm \cite{hidalgo2023sustainable}, there are four different levels for the evaluation and eventual improvement of energy consumption in AI (including, as in this paper, metaheuristics): just above the hardware level there is the programming language level, which includes not only the language itself, but also libraries and compilers or interpreters (inclusively named the {\em toolchain}. The latter was the topic of \cite{DBLP:conf/icsoft/GuervosGC23}, where our focus was to work on different JavaScript interpreters in order to discover which one used system energy more efficiently.

However, there are many user cases in which the language used by all or part of the metaheuristic implementation can also be chosen. A simple choice of language will greatly impact energy consumption, as shown in \cite{PEREIRA2021102609} or \cite{lima2016haskell}. In \cite{DBLP:conf/iwann/MereloRACML11}, we looked at the performance of different languages when implementing an evolutionary algorithm; in this paper, we will focus on the language level, before delving into specific language characteristics. Languages can be classified along many different axes: compiled vs. interpreted, low vs. high level, functional vs. procedural vs. object-oriented... In most cases, it is not a dichotomy, but a continuum; most interpreted languages, for instance, use Just-In-Time (JIT) compilers before actually running a script; most languages are also, nowadays, multi-paradigm, using procedural and functional as well as object-oriented features. Interpreted vs. compiled, low-level vs. high-level are still useful distinctions, however, from the point of view of performance as well as what interests us most in this line of research, energy consumption.

Thus, for this paper, we will try to work with languages that occupy different positions along those two axes. We will work with a high-level language, JavaScript, using the fastest implementation available, {\sf bun}; this is also an interpreted language, a high-level, compiled language, Kotlin, that compiles to bytecode of the Java virtual machine (JVM) and a low-level language, Zig, a relatively new language that is still not reached production, but is however used for {\sf bun} itself\footnote{Please note that there are no languages that are considered low-level and interpreted, although there are minimalistic interpreted languages like Lua \cite{ierusalimschy2007evolution}}. All these languages have toolchains that are free software and thus can be used without any kind of limitation.

These languages can also be divided along two different axes that impact on their energy consumption:\begin{itemize}
\item Memory management: it is done automatically in high-level languages, like JavaScript and Kotlin, while it involves a series of choices in the case of Zig. Inasmuch as allocating and releasing memory consumes energy, there is going to be a difference between having a runtime or interpreter make heuristic choices, or the developers making those decisions themselves.
\item Compilation: JavaScript is interpreted, Kotlin is compiled to bytecode and then interpreted by the JVM, and Zig is compiled to native code, but this also implies what happens with optimization: high-level languages take all decisions, while Zig will allow you to choose between different optimization levels; it also means that a different kind of overhead will be incurred when running a program: JavaScript will load the interpreter in memory, and then parse and run the program; Kotlin will actually use the Java virtual machine to run, and it will be loaded and then the bytecode parsed and run; finally, Zig creates executables, which will have some overhead due to standard linked libraries.
\end{itemize}

In general, this implies that although {\em a priori}, we can assume that low-level language, being {\em closer to the iron}, will consume fewer resources, the fact that high-level languages apply heuristics and best practices to those decisions might eventually mean that, on the default case, the balance might be tipped towards high-level languages; this is going to be the main focus of this paper.

Making comparisons of energy spent by different implementations needs, first, a methodology to make choices that are comparable across all three platforms; then what exactly is going to be measured needs to be established, and how to make those measurements so that they make differences stand out. As in previous papers, we will focus on two critical evolutionary algorithm functions \cite{abdelhafez2019component}: the  fitness function, as well as {\em genetic} operators. However, we will use a heavier fitness function in this case: Hierarchical If and only IF (HIFF) \cite{watson1998modeling} for independent measurement, as well as combine mutation and crossover when solving the OneMax optimization problem. In general, we are going for combined, or more complex, operations in this paper so that we can implicitly evaluate more features for every language, such as function calling or argument passing, which will have a different implementation, and thus energy overhead, in every language.

The rest of the paper is organized as follows: next, we present the state of the art in software engineering and its analysis of energy consumption of different software platforms, to be followed by the methodology we are going to apply in this paper, mainly concerned with evolutionary algorithms in \ref{sec:meth}. Then we will present the results of the experiments in \ref{sec:results}, and finally, we will discuss the results and draw some conclusions in \ref{sec:conclusions}.

\section{State of the art}
\label{sec:soa}

The shade of green of different languages has been repeatedly examined in the literature, at least since it actually became a concern in software engineering \cite{pinto2017energy}, very recently, indeed, this concern has been systematized in what are called the GREENER principles \cite{lannelongue2023greener}. These principles try to provide a foundation for Environmentally Sustainable Computer Science (ESCS), and are placed at different levels, from governance to Education. In this paper we are mainly concerned with the two Es, Estimation and Energy and embodied impact, as well as the R, research. These principles seek to monitor and then minimize the energy needs of computations; the Research principle, in turn, encourages to investigate on those topics. The GREENER principles try to kick-start a feedback loop that allows researches, and then developers in turn, to keep making decisions so that the same wallclock performance can be obtained with a minimal amount of energy.

We are interested on evolutionary algorithms, however, which have been studied from the point of view of energy consumption for some time \cite{10.1007/978-3-319-45823-6_51}; however it is interesting to note what these studies have focused in: population size \cite{diaz2022population}, hardware platform \cite{10.1007/978-3-319-45823-6_51}, the kind of algorithm \cite{garg2023analyzing} or the specific interpreter chosen to run the algorithm written in a specific language, JavaScript \cite{DBLP:conf/icsoft/GuervosGC23}. Although in this last case and in specific situation, energy savings of 90\% can be achieved, there are other possible choices that, in principle, might have a bigger impact without sacrificing performance (as would be the case when working with different hardware platforms).

And one of them is the programming language itself. A comprehensive and recent study \cite{PEREIRA2021102609}, that measure energy consumption on a general workload (the so-called CLBG corpus) show low-level languages like C, Rust or C++ coming up on top consistently. Mid-level languages like Java are placed 5th on the overall energy ranking, with almost double energy consumption. Interpreted languages like JavaScript (probably using the mainstream interpreter, node.js) are placed 17th, spending energy at 4 times the rate of C. The last language in the ranking, Perl, spends 2 orders of magnitude more than the baseline; Python is next to last, with a difference that is not as significant. Choosing the right platform is not all, however, \cite{lima2016haskell} show that the same algorithm implemented using different data structures might yield different levels of consumption; a similar problem is approached in \cite{connolly2023energy}, that shows that using th visitor pattern has a big impact in the energy profile of any program; however, the achieved reductions are very different depending on the language: while there is a slight reduction in the case of Java, the reduction achieved is dramatic in the case of C++. This probably shows that comparing platforms need to include higher-level component evaluation, that is, going beyond single functions.

In this paper, however, we will focus on the language itself, and how it consumes energy when applying the main operators  in evolutionary algorithms in such a way that higher-level language elements are also factored in. How we will be doing it is presented next.

\section{Methodology}
\label{sec:meth}

An energy profiling methodology will start with selecting a tool to perform measurements, then present the workload that is going to be used, proceed to the different systems that are going to measured, to end with the specific versions of the instruments and systems used; after this, the circumstances under which the measurement is going to take place need to be presented.

The measuring instrument was already chosen in a previous paper \cite{DBLP:conf/icsoft/GuervosGC23}. In general, there are system-wide as well as per-process measuring tools. We settled for {\sf pinpoint} \cite{9307947}, a command line tool that is under active development and takes per-process measure, which is more accurate than other system-wide tools.

In that paper we selected a single integer arithmetic fitness function, MAXONES, as well as the crossover operation. However, in this paper we are taking a wider view of the problem so we will try to work with fundamental building blocks, but with ones that involve a bigger span of the runtime system of the language. We will thus use two functions:\begin{itemize}
\item The Hierarchical If and only IF (HIFF) \cite{watson1998modeling} is an integer arithmetic function that works recursively, reducing a Boolean string of 0 and 1s by splitting it and applying the function to the halves; the final result will depend on the organization of 0s and 1s in the initial string, but will anyway involve many recursive function calls that will have to make use of the heap.
\item The other function will apply crossover to randomly selected pairs of binary strings, followed by mutation to every member of the resulting pair, and ONEMAX on that result. This is essentially 5 function calls, not as complicated as before, but it is a fundamental operation in evolutionary algorithms and will essentially test the ability to access random elements in string, as well as the creation of new ones (or the cloning of them, depending on the implementation)
\end{itemize}

We will use a workload of the same size as in the previous paper, 40K chromosomes, with chromosomes of different size: 512, 1024 and 2048 bits. This is a difference with respect to the previous paper, where we did not use 512 bits, using 4096 instead. We consider that the bigger size is not as realistic, and is relatively unlikely to be found in real problems; besides, the amount of time needed to compute HIFF was really high for the high-level JavaScript, so we decided to drop it so that experiments can take place in a relatively reasonable amount of time.

The languages have been chosen using a certain criterion: \begin{itemize}
\item JavaScript is, as shown in the state of the art, one of the languages that consume the least energy as proved in \cite{PEREIRA2021102609}; in our previous paper we have also found that using the {\sf bun} interpreter can results in savings as high as 90\% \cite{DBLP:conf/icsoft/GuervosGC23}. It is a high level, object oriented language that is, indeed, quite popular. It has been preferred over other languages that might have a higher popularity in metaheuristics, such as Python, since the above mentioned paper includes it as one of the languages that consume the most energy in a general payload; metaheuristics need not be an exception. At any rate, this paper is about choosing among kind of languages, so any result that is obtained might be extended to languages of the same kind; at the same kind, we propose a methodology for choosing the right system for metaheuristics, so more precise measurements would have to be performed on whatever alternative to JavaScript we want to introduce. The implementation of the above mentioned function is open source and hosted at \url{https://github.com/JJ/energy-ga-icsoft2023} with a free license. The actual code is the same used in the above mentioned paper.
\item Kotlin is a language that compiles to the JVM, and in that sense, it would be comparable to Java in terms of energy consumption. However, data structures as well as other runtime characteristics might differ, as well as the workload, so what we obtain in terms of ranking might be different to what \cite{PEREIRA2021102609} shows. As we mention above, and on a first approximation, results obtained here might be extended to other languages such as Java, Scala or Clojure that also target the JVM. Kotlin has not been the target of any popular EA library as far as we can tell, although it is mentioned in this context in works such as \cite{hollo2021statistical}. The implementation that has been used is also included in the same repository, and has been adapted from the one used in \cite{merelo2016ranking,merelo2017ranking}. In that study, Kotlin was one of the fastest, even faster than Java in one of the versions.
\item Finally, we use Zig as the low-level language instead of the more popular in EA circles C++ or in general terms Rust. The main reason why we chose it is because the interpreter we use for JS is written using it; so we should maybe expect less energy consumption when we lower the level of abstraction. On the other hand, it would be a totally new implementation of evolutionary algorithms, so this work could serve to introduce the language (and its possibilities) to practitioners. Again, the implementation is hosted in the same repository as the others used for this paper.
\end{itemize}

All experiments for this paper have been carried out in a Linux machine {\tt 5.15.0-94-generic \#104~20.04.1-Ubuntu SMP} using AMD Ryzen 9 3950X 16-Core Processor. These are the versions used for every tool and language:\begin{itemize}
\item {\sf pinpoint} does not have a version, but it has been compiled from commit {\tt 1578db07b1ee30318966d7a2097ee1bb219a9dc8}, October 26 2023.
\item {\sf bun} uses version 1.0.7.\footnote{Please note that at the time of writing this, many other versions have been published; we have used this one to be able to compare with previous papers. These same papers show that its performance and energy consumption have important improvements, so in case of close calls, we would recommend to take again measurements at the time of running your experiments}
\item {\sf zig} uses version 0.11.0. This version, released by August 3, 2023, is the last one at the time of writing this paper.
\item Kotlin version string is {\tt 1.9.22-release-704}; this includes the JVM version, OpenJDK 11.0.21.
\end{itemize}

All programs are run through a Perl script that captures and processes output, generating CSV data files that are committed to this repository, and also available under a free license. Instructions to compile and run it are also included in the repository; in general, all that is needed to make the results of this paper reproducible. All the code is tested also automatically, and tagged so that the exact version used in this paper can be retrieved.

Implementing an algorithm will always imply some choices in the specifics used to program it. In general, we opted for the default implementation (as suggested by tutorials), but explicitly these are the decisions we took:\begin{itemize}
\item {\sf bun} uses the same implementation as used previously, namely, mutable strings to represent the chromosome.
\item {\sf zig} being a low-level language, needs a bigger set of choices. We have used {\tt DefaultPrng} as random number generator, {\tt page\_allocator} as allocator, and arrays of byte-size integers ({\tt u8}) for the chromosomes. This is the default implementation of integers in the language. Please note that we are using here the actual values 0 and 1 instead of the characters '0' and '1'. The executable has been generated with default options too ({\tt optimize} for optimization).
\item {\sf Kotlin} uses again the same implementation as \cite{merelo2016ranking}, a {\tt BooleanArray} for every chromosome.
\end{itemize}

Please note that no sort of energy-wise optimizations have been performed on these implementations, since the main use case of this work would be scientists with no deep knowledge of specific languages that want to create energy-efficient implementations of their algorithms. Every one of the languages has different levers that could be used to optimize energy, but that is off focus in this paper. At any rate, if there is a close call in the results, the reader should take it into account, and again measure energy consumption for specific workloads.

Previously, the experiment runner eliminated the baseline energy consumption by subtracting the average consumption of an idle system during the average time the experiments took; however, that implied that the energy (and time) measured included {\em generation} of the chromosomes, as well as the operations themselves.

In this paper we will factor out that time, as well as the energy spent; this is usually a one-shot in evolutionary algorithms and not very significant in evolutionary algorithm workloads, and it will allow us to focus on the added energy consumption of the operations themselves; the results published in the next section will substract the average time and energy consumption of this operation, which is shown in figure \ref{fig:lion.setup}.

<<lion.setup, echo=F, message=F, fig.pos="h!tb", fig.height=4, fig.cap="Average running time and PKG energy consumption generating 40K chromosomes for the three languages (represented with different colors); dot size is proportional to the logarithm of the chromosome size">>=
library(dplyr)
library(ggplot2)
generate.chromosomes.bun <- read.csv("../data/generate-chromosomes-bun-lion-24.csv")
generate.chromosomes.bun  %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.bun.avg

generate.chromosomes.zig <- read.csv("../data/generate-chromosomes-zig-lion-24.csv")
generate.chromosomes.zig %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.zig.avg

generate.chromosomes.kotlin <- read.csv("../data/generate-chromosomes-kotlin-lion-24.csv")
generate.chromosomes.kotlin %>% group_by( size ) %>% summarise( mean.pkg = mean( PKG ), mean.seconds = mean( seconds ) ) -> generate.chromosomes.kotlin.avg

ggplot(generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun"))+ geom_point(data=generate.chromosomes.bun.avg, aes(x=mean.seconds,y=mean.pkg,color="Bun", size=log(size)))+geom_line(linewidth=1)+geom_point(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig", size=log(size)))+geom_line(data=generate.chromosomes.zig.avg,aes(x=mean.seconds,y=mean.pkg,color="Zig"),linewidth=1)+geom_point(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin",size=log(size)))+geom_line(data=generate.chromosomes.kotlin.avg,aes(x=mean.seconds,y=mean.pkg,color="Kotlin"), linewidth=1)
@

This Figure, that shows average energy consumed ({\tt mean.pkg}) vs. time taken ({\tt mean.seconds}), already allows us at least an initial comparison of the orders of magnitude of difference we should expect. Clearly Kotlin is the fastest and also the one that consumes the most energy; it is followed by {\sf zig}, although time as well as energy consumption grows very fast with the size of the chromosomes (here represented logarithmically as the dot size). {\sf bun} is the slowest, as well as the one that consumes the most energy, although we should note that for the bigger size (2048 bits) the consumption of energy is slightly lower for {\sf zig}.

<<lion.hiff.bun, echo=F, message=F>>=

hiff.bun <- read.csv("../data/pinpoint-v3-HIFF-13-Dec-09-06-34.csv")
hiff.bun %>% mutate( delta.pkg = PKG - generate.chromosomes.bun.avg$mean.pkg[ match( size, generate.chromosomes.bun.avg$size ) ], delta.seconds = seconds - generate.chromosomes.bun.avg$mean.seconds[ match( size, generate.chromosomes.bun.avg$size ) ] ) -> hiff.bun.delta

generation.bun <- read.csv("../data/pinpoint-v3-generation-13-Dec-10-10-00.csv")
generation.bun %>% mutate( delta.pkg = PKG - generate.chromosomes.bun.avg$mean.pkg[ match( size, generate.chromosomes.bun.avg$size ) ], delta.seconds = seconds - generate.chromosomes.bun.avg$mean.seconds[ match( size, generate.chromosomes.bun.avg$size ) ] ) -> generation.bun.delta

@

\section{Results}
\label{sec:results}

\section{Discussion, conclusion and future work}
\label{sec:conclusions}

Implementing an algorithm implies making choices at different levels, from the type of language you will use to the specific language that meet your needs. Settling for languages at a certain level of abstraction will help you to stop your decisions at that level, and not have to carry them further, thus saving precious time in the life cycle of an experiment. % Conclude which languages are better


\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR).

\bibliographystyle{splncs04}

\bibliography{energy,javascript,geneura}


\end{document}

