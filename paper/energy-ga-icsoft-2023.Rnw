\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}

\title{Green evolutionary algorithms and JavaScript: a study on different software and hardware architectures}

\author{Juan J. Merelo-Guervós\inst{1}\and
Mario García-Valdez\inst{2} \and
Pedro A. Castillo\inst{1}}

\authorrunning{Merelo-Guervós et al.}

\institute{Department of Computer Engineering, Automatics and Robotics and CITIC, University of Granada, Granada, Spain \and
Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico}

\maketitle

\begin{abstract} Energy-aware computing is the design and operation of hardware
and software systems to minimize their energy consumption. This requires
consideration of many variables and parameters, making it necessary to focus on
a single one or a few to obtain meaningful results; this is why, in this paper, we
will investigate the energy consumption of three JavaScript interpreters ({\sf
bun}, {\sf node.js}, and {\sf deno}) for evolutionary algorithms (EAs), a type
of population-based stochastic optimization algorithm. We expect different
energy budgets for running the same EA workload on these interpreters due to
their different conceptual designs. We will also compare the energy consumption
of the different operators and functions of the EA, to see if there are
differences in the energy consumption of the different
interpreters. Additionally, we will perform these measurements across different
architectures, homogeneous (Intel) and heterogeneous (ARM), to profile their
energy consumption.  To obtain these results, we will test different
tools to measure per-process energy consumption accurately. After choosing a
tool, we will perform experiments on a workload similar to an EA to measure the
energy consumption of EA-specific functions and operators for different problem
sizes. Finally, we will draw a conclusion on which JavaScript interpreter and
architecture are the most energy-efficient for EA workloads if energy is a limited
concern.
\end{abstract}

\keywords{Green computing, metaheuristics, JavaScript, energy-aware computing, evolutionary algorithms}

\section{\uppercase{Introduction}}
\label{sec:introduction}

Green computing
\cite{kurp2008green} refers to the design of hardware and/or software systems that are first conscious, and then minimize the environmental impact for a given workload. There are no fixed rules that apply to any field, which is why researchers usually settle on a specific field with well-known sets of algorithms and specific operators, such as evolutionary algorithms or metaheuristics \cite{novoa2021measuring}. Even within a narrow field, there are many possible choices. The language used to implement the algorithms is one of them, because implementation matters \cite{DBLP:conf/iwann/MereloRACML11}. Even within a language, there are many possible implementations, including simply the different versions that are periodically published; in some cases, different interpreters or compilers created by different teams with different intents or assumptions will also be available.

Our group has a 25-year-long history of working with JavaScript \cite{jj-ppsn98,jesus02,nodeo2014,DBLP:conf/gecco/GuervosCMES14,agajaj,DBLP:conf/evoW/ValdezTVGO13}. Despite its overall performance not being as good as other languages, given the availability of libraries such as NodEO \cite{nodeo2014} and the expressiveness and abundance of support for the JavaScript language, the time from idea inception to solution in production can actually be faster than with other languages. Also, given the fact that it can readily run on the browser, it is a good (and probably the only) choice for volunteer computing \cite{DBLP:journals/gpem/LaredoBGVAGF14,gecco07:workshop:dcor}.

Its evolution from a single-browser implementation to the many existing today makes it an attractive language to experiment with green computing. This evolution has taken it from a language designed in the late nineties for simple browser widgets and
client-side validations \cite{goodman2007javascript,flanagan1998javascript},
to being the one most widely used by developers, measured by their
GitHub repositories \cite{ogrady23:ranking}, occupying this position since 2014
\cite{ogrady14:ranking}, this popularity is because JavaScript its almost the exclusive language
needed for front-end programming (its only competition being mobile application development languages,
such as Swift or Kotlin, or languages transpiled to JavaScript, such as Dart or TypeScript),
while at the same time being strong for full-stack development, with solid
support for the back end, including application servers, middleware, and
database programming. Other popularity indices, such as
TIOBE\footnote{\url{https://www.tiobe.com/tiobe-index/}}, that take into account
other factors besides lines of code production, currently (October 2023) rank it as the
sixth, although it was also the most popular language in 2014. It can be
claimed, then, that it is among the most popular, if not the most popular
language among developers.

Due to its popularity and the fact that it has a continuously updated standard
\cite{ecma1999262}, there have traditionally been different virtual machines
(or interpreters) that are able to run JS. In its initial decade, browsers were the
only mainstream platform available\footnote{Although there were interpreters such as SpiderMonkey or Rhino available; they were not, however, as popular and mostly unused in production environments}; however, the introduction of Node.js running on
the V8 JavaScript Engine \cite{5617064} in 2009 gave it the mainstream support it has today.
The wide adoption of {\sf node.js}, along with the ECMA standard, inspired the development new interpreters like {\sf deno}
\cite{runtimeintroducing} (written in Rust) and, more recently, {\sf bun} \cite{bun}, programmed
in the Zig, a relatively new language for systems programming.

No wonder, then, that JavaScript is also a popular language for implementing
metaheuristics, especially evolutionary algorithms (EA). EAs
\cite{eiben2015evolutionary} are population-based stochastic optimization
algorithms based on the representation of a problem as a 
"chromosome", and the {\em evolution} of a population of these "chromosomes" by random
change (via so-called "genetic" operators such as mutation and crossover), 
evaluation of those chromosomes by what is often called the "fitness" function, and
selection for reproduction of those that achieve the best fitness values, emulating the survival of the
fittest of natural evolution. From the
early implementations in the browser
\cite{smith1996ga,jesusIWANN99,langdon2004global}, whole libraries
\cite{EvoStar2014:jsEO}, through complete implementations geared towards
volunteer computing \cite{2016arXiv160101607M}. After choosing the language \cite{DBLP:conf/iwann/MereloRACML11}, choosing an interpreter is the next decision that will impact whatever objective the researcher wants to reach, whether performance or energy efficiency; this will one of the main focuses of this paper.

Since the architecture of the different JS virtual machines is different,
and are created with languages with different focus (Rust is focused on memory
safety \cite{noseda2022rust}, while Zig is centered on simplicity and performance
\cite{zig}), different energy consumption profiles should be expected. All three
interpreters can (roughly) run the same, unmodified source code. What we intend
with this paper is to find a rule of thumb on which JS interpreter might give the lowest power
consumption, the maximum performance, or both, so that EA practitioners can
use it for deploying their applications to production.

In the first version published of this line of research
\cite{DBLP:conf/icsoft/GuervosGC23}, we established a methodology for choosing
an energy profile and performance measures in the versions of the interpreters
that were current at that time. In this paper we will update the methodology
and the results, using the current versions of the interpreters, and extend the
methodology to other architectures, namely Apple Silicon, which allows us to
gather some insight also on how energy results are achieved for the different
virtual machines.

The rest of the paper follows this plan: next, we will present the state of the
art; then we will describe the experimental setup in Section \ref{sec:setup};
results will be presented next in Section \ref{sec:res}, and we will end with a
discussion of results, conclusions and future lines of work.

\section{State of the art}

The power efficiency of CPUs (computations per kilowatt-hour) has doubled
roughly every year and a half from 1946 to 2009 \cite{koomey2011web}, this
improvement has been mainly a by-product of Moore's law, the trend of chip
manufacturers to decrease in half the size and distance between transistors
every two years. Unfortunately, the physical limits of electronics imply that
performance is no longer the single metric a processor is judged by; energy
efficiency is at least as important an important driver for current innovation;
creating the challenge of building more power-efficient systems
\cite{Richard2023}.


This challenge can be addressed at the hardware and software levels. At the
hardware level, it is leading towards the development of heterogeneous CPU
topologies that typically include two types of cores: "performance" and
"efficiency"; while the former vie for executing workloads as fast as possible,
the latter are geared towards running them without incurring in high energy
costs \cite{9988933}. Most modern processors, such as the Apple Silicon family,
as well as other ARM-based architectures, adopt this kind of architecture. We
also find increasingly processors that are designed with machine learning
workloads in mind, especially for trained models, such as the Google TPU or the
Apple Neural Engine \cite{9950755}. As the cited paper points out, integrating
these elements into algorithm implementations to increase speed and efficiency
presents a challenge.

These new challenges are tackled at the software level, with developers
proposing increasingly more energy-efficient algorithm implementations.
Algorithm comparatives nowadays include power efficiency as a performance
metric, these include encryption algorithms
\cite{mota2017comparative,thakor2021lightweight}, estimation models for machine
learning applications \cite{garcia2019estimation} and genetic programming (GP)
\cite{diaz2018fuzzy}, and code refactoring \cite{ournani2021tales}. Since
metaheuristics are so extensively used in machine learning applications, its
interest in research has grown in parallel to its number of applications. Many
papers focus on analyzing how certain metaheuristics parameters have an impact
on energy consumption.  Díaz-Álvarez et al. \cite{diaz2022population} study how
the population's size in genetic programming influences power consumption. In an
earlier work, centered on genetic algorithms (GAs)
\cite{10.1007/978-3-030-45715-0_8}, power-consumption of battery-powered devices
was measured for various parameter configurations including chromosome and
population sizes. The experiments used the OneMax and Trap function benchmark
problems, and they concluded that execution time and energy consumption do not
linearly correlate and there is a connection between the GA parameters and power
consumption.  In GAs, the mutation operator appears to be a power-hungry
component according to Abdelhafez et al. \cite{abdelhafez2019component}, in
their paper, they also report that in a distributed evaluation setting, the
communication scheme has a greater impact. Fernández de Vega et
al. \cite{10.1007/978-3-319-45823-6_51} experimented with different parameters
for a GP algorithm and concluded that hand-held devices and single-board
computers (SBCs) require an order of magnitude less energy to run the same
algorithm.

Of course, it is also a challenge to check how the software and hardware
architecture interact so that effectively the most efficient configuration is
used for every kind of workload. This is why, in this paper, we will focus on
the software side of the equation, and check how different JS interpreters
perform when running the same workload, as well as how they interact with the
"performance" and "efficiency" hardware cores of the Apple Silicon M1 processor.


\section{Methodology and experimental setup}
\label{sec:setup}

In this section, we will first present what can be measured and how it can be
done in the two platforms targeted in this paper, Intel and Apple Silicon; then
we will briefly describe how the experiments are run and the output is
processed in subsection \ref{ss:perl}.

\subsection{Measurements on an Intel-based platform}
There are many ways to measure the consumption of applications running in a
computer; besides measuring directly from the power intake, those running as
applications and tapping the computer sensors fall roughly into two fields:
power monitors and energy profilers \cite{cruz21}. Power monitors need
additional hardware to measure the power drawn by the whole machine; besides
being expensive, their setup is difficult, and it is complicated to measure
precisely how much a specific process consumes.

On the other hand, energy profilers are programs that draw information from
hardware sensors \cite{sinha2001jouletrack}, generally exposed through kernel
calls or higher-level wrapper libraries, to pinpoint consumption by specific
processes in a time period. Tools that give these measures, either with a
graphic or a command line interface, have been available for some time already,
and have become more popular lately. One of the mainstream processor
architectures, Intel, includes an interface called RAPL, or Running Average
Power Limit \cite{10.1145/2425248.2425252}. Essentially, it consists of a series
of machine-specific registers (MSRs) that contain information on the wattage
drawn by different parts of the architecture; the content of these registers
will be processed (through the corresponding library) and consumed by different
command line utilities. We will use these command-line utilities since they
produce an output that can be automatically processed and evaluated, which is
what we are looking for in this paper\footnote{Systems based on the AMD
architecture have a similar power profiling system called AMP with its
corresponding command line tool. However, we found that it was not well
documented, and excessively complicated for the purposes of this
article. Although not as complete, AMD processors also include the
aforementioned MSRs so RAPL-based utilities can run on them}.

Energy profiles, as measured by RAPL or other APIs, include different
\emph{domains} \cite{khan2015energy}, essentially the computing devices or
peripherals requiring the reported amount of energy.
DRAM or dynamic RAM, CORE, or GPU will report what happens on those specific devices,
with a core being every one of the computing units within the central processing
unit; other domains, like PKG or package, will report what happens in the
``package'', or CPU together with other devices in the chipset.

Different measuring command line tools were tested in \cite{DBLP:conf/icsoft/GuervosGC23}, finally choosing {\sf pinpoint}~\cite{9307947} (available from
  \url{https://github.com/osmhpi/pinpoint}), which is a tool that uses the RAPL
  interface, as well as the NVIDIA registers, and reports the power consumed by
these devices.

\subsection{Measurements on the Apple Silicon platform}
\label{ss:apple}

The Apple Silicon processor line is a series of ARM-based processors designed by Apple for their laptops and desktop computers. The architecture is fundamentally different from the x86 one that we have mentioned above, and has been designed with energy efficiency in mind. The processor has two kinds of cores: performance cores (or P-Cores) which include hyperthreading and are designed mainly for high-performance workloads, and efficiency cores (or E-Cores) which use less power. Which processors run the actual process is up to the operating system; besides the GPU, Apple Silicon also includes something called the Apple Neural Engine, which is a kind of tensor processing unit that works under some very specific conditions. These last two subsystems are not relevant for the purposes of this paper, but we are anyway interested in the kind of sensors that are available to measure power consumption for our workload.

The operating system has a set of parameters that fall under the management of
the so-called IOReport subsystem. This includes access to many different
metrics, but also to the ones we are interested in general power consumption,
as well as the activity of P- and E- cores. As in the case of the RAPL
metrics, there are several command-line tools that can be used to record them
during the execution of our workload:

\begin{itemize} 
\item {\sf powermetrics} is a command line tool that can be used to record the
    power consumption of the whole system, as well as the activity of the P-
    and E-cores. It's not designed to record specific commands, but it can
    be run in the background while we run other processes, showing measures
    with the sampling rate that is desired. 
\item {\sf pinpoint}, in its most recent versions \footnote{As a matter of
            fact, the code was incorporated in October 2023}, is also able
            to capture these metrics, with an output that has the same
            format as it does for other platforms and uses the same
            metrics. 
\end{itemize}

Of these two, we will use {\sf pinpoint} for the same reasons as in the case of
the Intel platform: it is easier to process the output, with no need to start
and stop the process before and after the command we are measuring finishes,
incurring thus in a certain amount of overhead. We can also leverage all the
scripts that we had created for processing the other platform's output.

\subsection{Running the experiments and processing the results}
\label{ss:perl}

A Perl script was created to perform the experiments; it launched the scripts
and collected results by analyzing the standard output and putting it in a CSV
format that would allow examination of the experiments.

The initial experiment consisted of a script that used the \texttt{saco-js}
library to perform the union of ``bags'', sets that can hold several copies of
the same item. 1024 sets were generated; these sets had 1024, 2048, 4096
elements. Then, a union of bags was performed on pairs of sets until
there was only one left. This is similar to some operations performed by
EAs, mainly related to merging populations. They do not
involve floating-point operations in any way.

The scripts that launched every kind of tool were slightly different, mainly because
the output needed to be processed in different ways (and different kinds of
information extracted). Additionally, \texttt{pinpoint}, which is the only tool
that does not need superuser privileges, sometimes returned 0 in energy
measures. This was an error, and those runs were discarded.

Finally, the scripts performed an additional task: since it is not possible to
disaggregate the readings for our program from the energy consumed by other
processes running at the same time, what we did was to run every program 15
times, compute the average time, and then use the same tool to measure the
energy consumption for the \texttt{sleep} program during the average amount of
time. The energy readings shown are the result of subtracting this measurement
from every one of the 15 other measurements taken so that we can analyze the
differential of energy that has been consumed by our programs; the result is
clipped at 0, since negative energy differentials would make no sense.


\section{Experimental results}
\label{sec:res}

On the JavaScript side, we used three different interpreters:\begin{itemize}
\item \texttt{bun} version 1.0.7
\item \texttt{deno} version 1.37.2, which includes the v8 library version
  11.8.172.13 and typescript 5.2.2
\item  \texttt{node.js} version 20.9.0
\end{itemize}

\texttt{bun} and \texttt{nodejs} are fully compatible, so they run exactly the
same code. The code for \texttt{deno} needed a small modification: the path to
the library had to be changed (since it does not use the \texttt{node\_modules}
to host installed modules), and it uses a different library for processing 
the command line arguments. Other than that, the business logic was exactly the same.

These were running in an Ubuntu version 20.04.1 with kernel version
5.15.0-69. The processor is an AMD Ryzen 9 3950X 16-Core. Since we will
not be testing in a pure Intel architecture, the complete RAPL API is
not going to be available; that is also why we will be experimenting
with different tools so that we can have an adequate coverage
of energy consumption for the commands we will be measuring.

<<r onemax, echo=F, fig.pos="h!tbp", fig.height=5, fig.cap="Boxplot of energy consumption vs. time taken for all three sizes and VMs.\\protect\\label{fig:onemax}">>=
library(ggthemes)
library(ggplot2)
onemax <- read.csv("../code/data/pinpoint-v2-onemax-30-Oct-19-03-28.csv")
onemax$size <- as.factor(onemax$size)
ggplot(onemax, aes(x=seconds,y=PKG))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
@

As was done in \cite{DBLP:conf/evoW/MereloCBRGFRV16}, which was focused on
wall clock performance, the experiments will be focused on the key operations
performed by an EA: evaluation of fitness and "genetic" operators like mutation
and crossover. We will first measure again the performance of the three
interpreters involved, and then compare these new measurements to old versions
of the same VMs.

\subsection{Comparing performance of JS interpreters}
\label{ss:perf}

We will repeat the setup in the initial exploration, to check the
energy consumption for the processing of 40000 chromosomes, a number chosen to
take a sizable amount of memory, but also on the ballpark of the usual number of
operations in an EA benchmark, it is also compact enough to avoid issues with garbage collection in memory,
something that was detected after the
initial exploration.  Experiments were repeated for the same chromosome size as
before, 1024, 2048, and 4096, and for the three JS virtual machines
used. Although the business logic is exactly the same for the experiments, the
script has two versions, one for {\sf deno} and the other for {\sf
bun/node}, due to the different way they have of reading command-line
arguments. This does not affect the overhead in any way. Code, as well as the
data resulted from the experiments and analyzed in this paper, are released with
a free license (along with this paper) from the repository
\url{https://github.com/JJ/energy-ga-icsoft-2023}.

First, we will evaluate a typical fitness function, OneMax, which counts the
number of ones in a binary (1s and 0s) string. This type of function, which
check the values of bits in a string and assign an integer value to it,
is found in many papers focused on evaluating EAs,
including parallel versions \cite{DBLP:conf/gecco/GuervosV18}.

The results are shown in Figure \ref{fig:onemax}. This already shows that time,
as well as energy consumption, for {\sf node} is higher; just check the
separation of the squares representing individual experiments in that
interpreter to the rest of the values for the same color; this separation
increases with chromosome size. But this paper focuses on energy consumption,
which we summarize next in Figure \ref{fig:onemax:energy}.

%
<<r onemax.vms, echo=F, fig.pos="h!tbp", fig.height=4, fig.cap="Boxplot of PKG measurements for the OneMax problem and the three different virtual machines.\\protect\\label{fig:onemax:energy}">>=
ggplot(onemax, aes(x=size,y=PKG))+geom_boxplot(aes(fill=VM))+ylim(0, NA)+theme_tufte()
onemax$kwh <- onemax$PKG * 2.77778e-7
onemax$cost.Spain <- onemax$kwh * 20
@
%

The figure shows the almost-flat growth of energy consumption for {\sf bun}.
How consumption grows for {\sf deno} is weird, since it takes less energy when
the chromosome is bigger (4096). Once again, {\sf node} is the bigger energy
guzzler, consuming up to 3 times more than {\sf deno} on average, and more than
6 times as much as {\sf bun}. We will see how this is reflected in monetary
terms, taking into account that the cost in Spain today is around 0.2€/kWh.
This cost, shown in table \ref{tab:onemax:cost}, reaches almost one-hundredth
of a euro for the most "expensive" VM, {\sf node}; that gives you an idea of
the kind of cost the algorithms have, and also how this cost decreases almost
an order of magnitude if {\sf bun} is used.

<<r onemax.cost, echo=F, message=F>>=
library(dplyr)
onemax.cost <- onemax %>% group_by( size, VM) %>% summarise( average = mean( cost.Spain ), sd = sd( cost.Spain))
library(kableExtra)
kable(onemax.cost, caption="Estimated cost of the OneMax runs for every VM and size, in €-cents. \\protect\\label{tab:onemax:cost}")
@

The crossover operation involves copy operations between strings, as well as the
creation of new strings. We will again generate 40K chromosomes and group them
in pairs; these strings will be crossed by interchanging a random
fragment from one to the other and back. The resulting pairs will be stored in
an array, which is eventually printed. The result of every experiment
is shown in an energy vs. wall clock time chart in Figure \ref{fig:xover}.

<<r crossover, echo=F, fig.pos="h!tbp", fig.height=4, fig.cap="PKG consumption, in Joules, vs. time in seconds, for the crossover and the three different virtual machines.\\protect\\label{fig:xover}">>=
crossover <- read.csv("../code/data/pinpoint-v2-crossover-30-Oct-18-11-43.csv")
crossover$size <- as.factor(crossover$size)
ggplot(crossover, aes(x=seconds,y=PKG))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
@

The scenario is remarkably similar to the one shown in Figure \ref{fig:onemax}.
In the two cases, {\sf bun} achieves the top performance and lowest energy
consumption, and {\sf node} is the worst. Average energy consumption is shown as a
boxplot in Figure \ref{fig:crossover:energy}.

%
<<r crossover.energy, echo=F, fig.pos="h!tbp", fig.height=4, fig.cap="Boxplot of PKG measurements for the crossover operator and the three different virtual machines.\\protect\\label{fig:crossover:energy}">>=
ggplot(crossover, aes(x=size,y=PKG))+geom_boxplot(aes(fill=VM))+ylim(0, NA)+theme_tufte()
@
%

Here we can see again the surprising fact that {\sf deno} takes the same amount
of energy, on average, as {\sf node} for size 2048, in a similar case to what
happened for OneMax (shown in Figure \ref{fig:onemax:energy}). The difference
between the thriftiest, {\sf bun}, and the heaviest consumer, {\sf node}, is
approximately three times, in this case, less than in the case of the OneMax fitness
function.

\subsection{Comparison between different interpreter versions}

Since \cite{DBLP:conf/icsoft/GuervosGC23} was written, the interpreters used in
that and this paper have evolved; {\sf bun} has gone from beta to production
with its 1.0 version, while {\sf node.js} has gone from its LTS (long-term
support) version 18 to 20. While new versions always try to improve performance,
it is not a given that they do so while keeping a low-energy profile or
optimizing for energy consumption in any way. In this subsection, we will
compare the energy consumption of the different versions of the interpreters
used in the previous installment of this line of research to see if there are
any significant differences. In that paper, the versions for the three JS
interpreters were:

\begin{itemize}
\item \texttt{bun} version 0.5.8
\item \texttt{deno} version 1.32.1, which includes the v8 library version
  11.2.214.9 and typescript 5.0.2
\item  \texttt{node.js} version 18.5.0
\end{itemize}

Current versions, up-to-date by November 1st 2023, are shown above in section \ref{sec:res}.

<<r load.process.data, echo=F, message=F>>=

onemax %>% group_by( size, VM) %>% summarise( average = mean( PKG ) ) -> onemax.avg
onemax.old <- read.csv("../code/data/pinpoint-vms-onemax-11-Apr-10-19-29.csv")
onemax.old %>% group_by( size, VM) %>% summarise( average = mean( PKG ) ) -> onemax.old.avg
onemax.avg.ratio <-data.frame( size = onemax.avg$size, vm = onemax.avg$VM, ratio.onemax = onemax.avg$average / onemax.old.avg$average)

crossover %>% group_by( size, VM) %>% summarise( average = mean( PKG ) ) -> crossover.avg
crossover.old <- read.csv("../code/data/pinpoint-vms-crossover-11-Apr-17-06-52.csv")
crossover.old %>% group_by( size, VM) %>% summarise( average = mean( PKG ) ) -> crossover.old.avg
crossover.avg.ratio <-data.frame( size = crossover.avg$size, vm = crossover.avg$VM, ratio.crossover = crossover.avg$average / crossover.old.avg$average)

improvements <- merge( onemax.avg.ratio, crossover.avg.ratio, by = c("size", "vm"))
kable(improvements, caption="Ratio of PKG energy consumption, new version vs. old version for OneMax and crossover. \\protect\\label{tab:improvements}",row.names=F,col.names=c("VM","Size","OneMax","Crossover"))

@


In Table \ref{tab:improvements}, we can see the ratio of energy consumption for
these old versions vs. the new ones; it is obvious that there are changes, and
mostly improvements, making new versions better for green computing; however,
there are differences across interpreters, sizes, and the workload
involved. While in general {\sf bun} spends less energy, sometimes remarkably
so, like in the case of the OneMax function and the smallest size, there are
cases, like Crossover for the medium size, where it can be slightly worse. {\sf
deno} is the interpreter that has the most irregular energy consumption changes;
while it is remarkably worse for the smallest size, it shows very good
improvements in the others. {\sf node.js} shows a more consistent improvement,
improving energy consumption by roughly 50\% in the case of OneMax, and slight
improvements of around 10\% in the case of Crossover.

This tells us that, in general, we should always try to use the latest version
of the interpreter, as it will most likely be more energy efficient. However,
benchmarking these new versions is still necessary, as there are cases where the
new version is not better than the old one. At the same time, these results
confirm that {\sf bun}, even after the introduction of the 1.0 version, is
still the most energy-efficient interpreter, and it is probably a reasonable
rule-of-thumb to make it our first choice when dealing with evolutionary
algorithms workloads.

As has been indicated earlier, Apple Macs have a different architecture, called
Apple Silicon, using heterogeneous cores, the "P" and "E" cores. The chosen
tool, {\sf pinpoint}, yields measurements for every code subset, as well as
DRAM; we have performed a series of measurements with these interpreter
versions:

\begin{itemize}
\item \texttt{bun} version 1.0.9
\item \texttt{deno} version 1.36.4
\item  \texttt{node.js} version 20.9.0
\end{itemize}

As in the in the previous cases, we have performed measurements for the OneMax fitness function and the Crossover operator; the platform was a MacBook Air M1 with 16GB of RAM and macOS Ventura 13.2.1. The results are shown in Figure \ref{fig:onemax:mac} and Figure \ref{fig:onemax:mac}.

<<onemax.mac, echo=F, fig.pos="h!tbp", fig.show="hold", out.width="32%", fig.cap="Boxplot of energy consumption for the OneMax fitness function: RAM (left), \"efficiency\" CPUs (middle), \"performance CPUs\" (right) vs. time taken for all three sizes and VMs, in a Mac.\\protect\\label{fig:onemax:mac}">>=

onemax.mac <- read.csv("../code/data/pinpoint-mac-onemax-7-Nov-10-35-09.csv")
onemax.mac$size <- as.factor(onemax.mac$size)
ggplot(onemax.mac, aes(x=seconds,y=RAM))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
ggplot(onemax.mac, aes(x=seconds,y=ECPU))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
ggplot(onemax.mac, aes(x=seconds,y=PCPU))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
onemax.mac$CPU <- onemax.mac$ECPU + onemax.mac$PCPU
@

The situation shown in that figure is remarkably similar, in the sense that node.js consumes more energy than the other two, and {\sf bun} is at the same time faster and consumes less energy. There are, however, some specifics in how Apple Silicon measures and spends the energy; from left to right, we can see that the {\em scale} of  the three charts is quite different: the bulk of the energy is spent by the "P" cores, that is, the performance cores. The same happens in the case of Crossover, shown in Figure \ref{fig:crossover:mac}. This implies that, for this workload, the "E" cores are used at a very low level, if at all. The total energy spent by the cores is also much higher than the one spent by the RAM.

<<r crossover.mac, echo=F, fig.pos="h!tbp", fig.show="hold", out.width="32%", fig.cap="Boxplot of energy consumption for the crossover operator in RAM (left), \"efficiency\" CPUs (middle), \"performance CPUs\" (right) vs. time taken for all three sizes and VMs, in a Mac.\\protect\\label{fig:crossover:mac}">>=

crossover.mac <- read.csv("../code/data/pinpoint-mac-crossover-7-Nov-11-09-36.csv")
crossover.mac$size <- as.factor(crossover.mac$size)
ggplot(crossover.mac, aes(x=seconds,y=RAM))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
ggplot(crossover.mac, aes(x=seconds,y=ECPU))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
ggplot(crossover.mac, aes(x=seconds,y=PCPU))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
crossover.mac$CPU <- crossover.mac$ECPU + crossover.mac$PCPU
@

We will try to compare this energy profile with the one obtained previously in an Unix machine with an AMD processor. Although they are not entirely comparable, PKG is equivalent to the sum of P and E cores.

<<mac.rations, echo=F,message=F,warning=F>>=
onemax.mac %>% group_by( size, VM) %>% summarise( average = mean( CPU ) ) -> onemax.mac.avg
crossover.mac %>% group_by( size, VM) %>% summarise( average = mean( CPU ) ) -> crossover.mac.avg

onemax.mac.ratio <-data.frame( size = onemax.avg$size, vm = onemax.avg$VM, ratio.onemax = onemax.avg$average / onemax.mac.avg$average)
crossover.mac.ratio <-data.frame( size = crossover.avg$size, vm = crossover.avg$VM, ratio.onemax = crossover.avg$average / onemax.mac.avg$average)
improvements.mac <- merge( onemax.mac.ratio, crossover.mac.ratio, by = c("size", "vm"))
kable(improvements.mac, caption="Ratio of CPU energy consumed by the desktop machine over the MacAir with Apple Silicon M1. \\protect\\label{tab:improvements:mac}",row.names=F,col.names=c("VM","Size","OneMax","Crossover"))
@

What we see in Table \ref{tab:improvements:mac} is that, in all cases, the workload under study consumes less energy in the Apple Silicon architecture than in the desktop machine. A priori, this should be expected, since energy management is one of the features of portable machines, and is probably not exclusive of Apple Silicon. What is surprising, however, is that in some cases the improvement is quite significant: the crossover operation performed by {\sf node.js} can spend 9 times less energy in the Apple Silicon device; OneMax more or less the same in {\sf deno}. Even {\sf bun}, characterized by the lowest energy profile, can spend even less energy in this case; for instance, on average {\sf bun} will spend \Sexpr{onemax.mac.avg$average[1]} Joules in the MacBook Air for OneMax with 1024 bits, while the desktop machine will spend \Sexpr{onemax.avg$average[1]} Joules.

<<avg.times, echo=F, message=F>>=
onemax %>% group_by( size, VM) %>% summarise( average = mean( seconds ) ) -> onemax.avg.time
onemax.mac %>% group_by( size, VM) %>% summarise( average = mean( seconds ) ) -> onemax.avg.time.mac
@

What is remarkable, in this case, is also that the laptop is {\em faster}, with the workload taking on average \Sexpr{onemax.avg.time.mac$average[1]} seconds on the MacBook Air for OneMax with 1024 bits, and  \Sexpr{onemax.avg.time$average[1]} in the other case; all across the board, the MacBook Air is faster.

\section{Conclusions}
\label{sec:conc}

This paper investigates the energy efficiency of various JavaScript
interpreters and architectures under Evolutionary Algorithm (EA) workloads. We
analyze the energy consumption of brief scripts extensively used within these
algorithms and how these energy expenses scale as the chromosome size
increases. 
We have developed a methodology that enables the precise measurement of energy
consumption for individual processes; we also adopted a multi-platform tool,
\pinp, that can give accurate estimations of sensor readings, discarding
experiments where that estimation was not adequate; we calibrated this tool by
comparing its readings with other tools, which were also evaluated for the same
purpose and eventually discarded.
Further, we adopted a benchmarking strategy akin to the one used to measure
performance, enabling us to pinpoint energy expenditure for specific operations
while discarding the noise produced by executing a complete algorithm. Such an
approach excludes the interference of different operations, applied in
different proportions, that could obfuscate actual energy costs when blended
within the whole algorithm.
Testing short code paths, consistent with the suggestions of
\cite{10.1145/2425248.2425252}, makes it easier to understand their individual
contribution to the overall consumption of the algorithm, thus paving the way
for more targeted optimization—either by refining the code itself or by
adjusting its frequency within the algorithm.

During the exploratory data analysis, we have established that, in Linux and
MacOS machines, \pinp{} can be profitably used to measure per-process energy
consumption, as long as these measurements are repeated and the process
% Is not clear what 'repeated' means, as long as the measurements are the average of 
% several (representative sample) measurements? - M  
themselves include short snippets of business logic; this tool should be
preferred over others that are either less accurate or simply take into account
different aspects of energy consumption.

The core objective of this paper, however, was to check which JavaScript
interpreter and computing architecture are optimal for minimizing energy
consumption; the experiments have reliably confirmed {\sf bun} to be the
superior interpreter across all tested architectures. It not only consumes less
energy for all the range of chromosome sizes; it also exhibits enhanced time
efficiency and can run applications written for Node (mostly) unmodified; its
consumption also scales better with problem size. These advantages may stem
from its design philosophy and the use of Zig. This language prioritizes
compile-time safety and manual memory allocation by default and avoids hidden
control flow. With {\sf bun} recently achieving its 1.0 milestone, it is our
pick for workloads of this kind.

If using {\sf bun} is an issue, {\sf deno} might be a good alternative. Except in very
specific cases, it is going to be faster and consume less energy than {\sf
node}, even more so when memory requirements are high. According to our initial
exploration, it will also consume less energy {\em per second}; thus for
workloads that take roughly the same time, it will be a better candidate than
{\sf node}. As an inconvenience, it needs minor modifications for the code to
run, at least if you need core or other kinds of external libraries; its core
library modules are different from those used in {\sf node/bun}, although that
need not be a disadvantage per se, since it is not complicated to design
algorithmic code that is interpreter-independent.

The previous two points imply that energy-wise (or even performance-wise),
there are no good reasons to use {\sf node.js} for running EAs. Except if the
business logic uses specific, early-adoption, or some features that, for some
reason, do not work with {\sf bun} yet, we advise anyone to keep using {\sf
bun} for these kinds of workloads.


By testing different versions of the interpreters, we can affirm also that the advantage of {\sf bun} over the other interpreter is consistent in time; in some cases there are dramatic reductions in consumption in new versions. However, it is also true that {\sf bun} has gone from beta to production, so the same kind of reductions might not be expected in the near future. Since it is impossible to preview whether energy consumption optimization will proceed at the same rate for every other interpreter, we will still need to test new versions, maybe under a reduced benchmark. The interpreter architecture, which is based in three different languages, might still give some edge for {\sf bun} over {\sf deno} and for this one over {\sf node.js}. But in absence of any principled certainty on this, we can only advice to keep benchmarking new versions of the interpreters for the workloads we are interested with, maybe in small samples so that decisions can be made quickly.


As we have indicated in the experimental section, the extensive advantage that
{\sf bun} has over the other interpreters does not leave much room for adopting
different benchmarks that could make that ranking vary; at any rate, these
experiments have shown how much faster and energy-saving {\sf bun} is (from 1/3
to 1/6 the energy consumed by {\sf node}). Still, it would be interesting to
know what happens to this gap under different operations like selection or a
different kind of mutation.

Another interesting avenue of research is the way different architectures
affect energy consumption, not only at the processor design level but also at
the machine design level. Other computers with different cooling strategies,
passive or active, will spend energy differently and interact with workloads
and interpreters in non-trivial ways. Even an architecture, like the Apple
Silicon M1, in a non-professional laptop can outperform a professional
workstation desktop computer and consume less energy in the process. Since
researchers generally have different kinds of computers available, our
measurements here indicate that, whenever possible, the Apple Silicon M1
architecture should be preferred.

Although Evolutionary Algorithms (EAs) typically do not rely on GPUs, certain
fitness functions operating on floating-point numbers may benefit from GPU
acceleration. Investigating how JavaScript interpreters manage such tasks when
leveraging GPU capabilities presents an intriguing avenue for future research;
how interpreters work in this area could be an interesting future line of work;
additionally to GPUs, Apple includes what is called the Apple Neural Engine.
Although this is geared mainly towards tensor processing, implementing EAs on
this platform is a challenge due to its specialized focus. Nonetheless,
exploring its application in this context and assessing the impact on energy
consumption would be a valuable contribution to the field. 

In this paper, mutation is not examined as a micro-operation, it will likely not have
much influence; however, other operations like selection, with more complexity,
require energy expenses that scale in a wholly different way. In general,
building up a more general instance of a single generation in an evolutionary
algorithm will give us a broader perspective on energy profiles without losing
sight of the individual operations that make it up and the specific energy
costs of each of them. At the same time, in this paper, we have experimented
with a single data structure to represent the chromosomes; current EAs use
additional data structures, and they will have different energy profiles.
Fixing other parameters (like interpreters and architecture) and working on
them will also give us a path for making evolutionary algorithms greener.

\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR) and Project 18186.23-P of 2023 TecNM research grants.


\bibliographystyle{apalike}
{\small
\bibliography{energy,javascript,geneura}}


\end{document}

