\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\pinp}{\texttt{pinpoint}}
\newcommand{\lik}{\texttt{likwid}}

\begin{document}

\title{Energy consumption of evolutionary algorithms in JavaScript}

\author{ 
  Juan J. Merelo-Guervós\inst{1}\orcidID{0000-0002-1385-9741}
and
  Mario García-Valdez\inst{2}\orcidID{0000-0002-2593-1114}
and
  Pedro A. Castillo\inst{1}\orcidID{0000-0002-5258-0620}
}
\institute{Department of Computer Engineering, Automatics and Robotics, University of Granada, Granada, Spain \and
Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico\\
\email{jmerelo@ugr.es, mario@tectijuana.edu.mx, pacv@ugr.es}
}


\maketitle

\begin{abstract}


\keywords{Green computing, metaheuristics, JavaScript, energy-aware computing, evolutionary algorithms}
\end{abstract}

\section{\uppercase{Introduction}}
\label{sec:introduction}

From a language designed in the nineties for simple browser widgets and
client-side validations \cite{goodman2007javascript,flanagan1998javascript},
JavaScript is nowadays the language most widely used by developers in their
GitHub repositories \cite{ogrady22:ranking}, occupying this position since 2014
\cite{ogrady14:ranking}, mainly because it is almost exclusively the language
needed for front-end programming (competing only with app development languages,
such as Swift or Kotlin, or languages transpiled to JavaScript, such as Dart),
while at the same time being strong for full-stack development, with solid
support for the back end, including application servers, middleware, and
database programming. Other popularity indices, such as
TIOBE\footnote{\url{https://www.tiobe.com/tiobe-index/}}, that take into account other
factors besides lines of code production, currently (2023) rank it as the seventh,
although it was also the most popular language in 2014. It can
be claimed, then, that it is among the most popular, if not the most popular
language in current development.

Due to its popularity and the fact that it has a
continuously evolving standard \cite{ecma1999262}, traditionally, there have
been different virtual machines (or interpreters) to run its programs. During
the first years, browsers were the only running platform available; however, the
introduction of Node.js running on the V8 JavaScript Engine \cite{5617064} gave
it the popularity it has today; this popularity, in turn, provoked new
interpreters to spawn like {\sf deno} \cite{runtimeintroducing} (written in
Rust) and {\sf bun} \cite{bun} programmed in the relatively unknown language
Zig.

No wonder, then, that JavaScript is also a popular language for implementing
metaheuristics, especially evolutionary algorithms (EA). EA
\cite{eiben2015evolutionary} are population-based stochastic optimization
algorithms based on the representation of a problem as a (often binary)
"chromosome", and {\em evolution} of population of these "chromosomes" by random
change (via "genetic" operators, mutation and crossover) and survival of the
fittest (evaluation of those chromosomes via a so-called "fitness" function, and
selection and reproduction of those that achieve the best values).  From the
early implementations in the browser
\cite{smith1996ga,jesusIWANN99,langdon2004global}, whole libraries
\cite{EvoStar2014:jsEO}, through complete implementations geared towards
volunteer computing \cite{2016arXiv160101607M}. However, one of the criticisms
leveraged towards these implementations is the (possible) lack of speed when
compared to other compiled languages (mainly Java, very popular in
metaheuristics implementations, or C++).

This is why, since implementation matters \cite{DBLP:conf/iwann/MereloRACML11},
choosing the right interpreter is going to have a significant impact on the performance
of any workload; if you decide to choose JavaScript for any reason (such as
seamless client/server integration, or be able to run your algorithm either on
the browser or from the command line if desired) knowing which VM delivers the
best performance is essential, either from the scientific, or software engineering
points of view.

At the same time, with the advent of the concept of green computing
\cite{kurp2008green}, it becomes increasingly important to measure not only the
raw wall clock performance (which was the focus of papers such as
\cite{DBLP:conf/evoW/GuervosBCRGRVHR17}), but also to achieve a certain level
of performance with a certain amount of energy consumption, or else to minimize
the consumption needed to run a certain workload. This will be the main focus
of this paper; since the core of the different JS virtual machines is
different, and are created with languages with different focus (Rust is focused
on memory safety \cite{noseda2022rust}, Zig based on simplicity and performance
\cite{zig}), different energy consumption should be expected. Since all three
languages can (roughly) run the same, unmodified source code, what we intend
with this paper is to advise on which JS interpreter might give the lowest
power consumption, the maximum performance, or both, so that EA practitioners can target it for their development.

In a previous stage of this research \cite{js:energy}, we established a methodology and chose the tools we were going to use for these energy measurements. In this edition we will update the results looking at different factors\begin{itemize}
\item Test new version of the virtual machines for energy consumption, since in general these evolve towards more efficient operation; at any rate, the balance of results might change in these new versions in unexpected ways.
\item Test also in different power consumption environments, including an unplugged laptop, so that the interplay between the virtual machine and the power management can be observed; we will also test in a low-power laptop (as compared with a power-hungry desktop machine)
\item More complete operation of an evolutionary algorithm will be tested: the ubiquitous mutation will be also tested, separately and in combination with crossover, to see what kind of power consumption profile it adds.
\end{itemize}


The rest of the paper follows this plan: next we will present the state of the
art; then we will describe the experimental setup in Section \ref{sec:setup};
results will be presented next in Section \ref{sec:res}, and we will end with a
discussion of results, conclusions and future lines of work.

\section{State of the art}

% First, CPU and general algorithmic impact on power consumption

The power efficiency of CPUs (computations per kilowatt-hour) has
doubled roughly every year and a half from 1946 to 2009
\cite{koomey2011web}, this improvement has been mainly a by-product
of Moore's law, the trend of chip manufacturers to decrease in half
the size and distance between transistors every two
years. Unfortunately, it is expected that physical limits of
electronics will slow down this miniaturization in the near future.
Nonetheless, energy efficiency is becoming the most important metric
of performance and selling point in hardware development, and it is an
important driver for current innovation. The challenge of building
more power-efficient systems, can be addressed at the hardware and
software levels. In the software level, developers focus their
attention on the energy consumption of software, proposing
optimizations for more energy-efficient algorithm implementations.
Algorithm comparatives nowadays include power efficiency as a
performance metric, these include encryption algorithms
\cite{mota2017comparative,thakor2021lightweight}, estimation models
for machine learning applications \cite{garcia2019estimation} and
genetic programming (GP) \cite{diaz2018fuzzy}, and code refactoring
\cite{ournani2021tales}. Since metaheuristics are so extensively used
in machine learning applications, its interest in research has grown
in parallel to its number of applications. Many papers focus on
analyzing how certain metaheuristics parameters have an impact on
energy consumption.  Díaz-Álvarez et al. \cite{diaz2022population}
studies how the populations size of EAs
influences power consumption. In an earlier work, centered on genetic
algorithms (GAs) \cite{10.1007/978-3-030-45715-0_8}, power-consumption
of battery-powered devices was measured for various parameter
configurations including chromosome and population sizes. The
experiments used the OneMax and Trap function benchmark problems, and 
they concluded that execution time and energy consumption do not
linearly correlate and there is a connection between the GA parameters
and power consumption.  In GAs, the mutation operator appears to be a
power-hungry component according to Abdelhafez et
al. \cite{abdelhafez2019component}, in their paper they also report
that in a distributed evaluation setting, the communication scheme has
a grater impact. Fernández de Vega et
al. \cite{10.1007/978-3-319-45823-6_51} experimented with different
parameters for a GP algorithm and concluded that hand-held devices and
single-board computers (SBCs) required an order of magnitude less
energy to run the same algorithm.


\section{Methodology and experimental setup}
\label{sec:setup}

From the different ways to measure energy consumption \cite{cruz21}, in \cite{js:energy} we chose {\sf pinpoint}~\cite{9307947}, a tool that uses the RAPL (Running Average Power Limit \cite{rapl}) interface, to report the power consumed. This tool was on one side accurate enough to take the measurements we needed and on the other hand it was taking the measures that we needed, so it will be the one used also in this paper. This tool sometimes returns 0 in energy measures. This was an error, and those runs were discarded and the run repeated until the desired number is reached.

On the JavaScript side, there are many interpreters available and under development, including those embedded in web browsers. Since these are more difficult to measure, and include consumption by the browser itself, we will focus on command line interpreters, and only those in more active development, including those we are most interested in: the high performance virtual machines that were released recently. These are the versions we use:\begin{itemize}
\item \texttt{bun} version 0.6.4
\item \texttt{deno} version 1.34, which includes the v8 library version
  11.5.150.0 and typescript 5.0.4
\item  \texttt{node.js} version 18.16.0
\end{itemize}

These were running in an Ubuntu version 20.04.1 with kernel version
5.15.0-69. The processor is an AMD Ryzen 9 3950X 16-Core; only some registers are available in this case since it is a processor with a different architecture.

A Perl script was created to run the experiments; it executed the scripts
and collected results by parsing the standard output and putting it in a CSV
format that would allow examination of the experiments. As indicated in \cite{js:energy}, consumption for a no-op task run in the same environment was substracted from the reading taken, before computing the average in this script.

\section{Experimental results}
\label{sec:res}

As was done in \cite{DBLP:conf/evoW/MereloCBRGFRV16}, which was focused on
wallclock performance, the experiments will be focused on the key operations
performed by an EA: evaluation of fitness and "genetic"
operators like mutation and crossover. 
What we will do is, repeating the setup in the initial exploration, 
check the energy consumption for the processing of
40000 chromosomes, a number chosen to take a sizable amount of memory, but also
on the ballpark of the usual number of operations in an EA
benchmark, it is also small enough to not create garbage collection problems
with the memory, something that was detected after the initial exploration.
Experiments were repeated for the same chromosome size as before, 1024, 2048,
and 4096, and for the three JS virtual machines used. Although the business
logic is exactly the same for the experiments, the script run comes in two
versions, one for {\sf deno} and the other for {\sf bun/node}, due to the different
way they have of reading command-line arguments. This does not affect the
overhead in any way. Code, as well as the data resulted from the experiments
and analyzed in this paper, are released with a free license (along with this
paper) from the repository \url{https://github.com/JJ/energy-ga-icsoft-2023}.

<<r onemax, echo=F, fig.show="hold", out.width="30%", fig.cap="Comparison between different versions of the VMs; left: node.js, center: bun, right:deno\\protect\\label{fig:onemax}">>=
library(ggplot2)
library(ggthemes)
library(stringr)
onemax.icsoft <- read.csv("../code/data/pinpoint-vms-onemax-11-Apr-10-19-29.csv")
onemax.icsoft$size <- as.factor(onemax.icsoft$size)
onemax.icsoft$VM <- str_trim(onemax.icsoft$VM)
onemax <- read.csv("../code/data/pinpoint-vms-onemax-29-May-17-45-44.csv")
onemax$size <- as.factor(onemax$size)
onemax$VM <- str_trim(onemax$VM)
ggplot(onemax[onemax$VM == "node",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, stroke=2)+geom_point(data=onemax.icsoft[onemax.icsoft$VM == "node",],pch=21, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
ggplot(onemax[onemax$VM == "bun",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, stroke=2)+geom_point(data=onemax.icsoft[onemax.icsoft$VM == "bun",],pch=21, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
ggplot(onemax[onemax$VM == "deno",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, size=4, stroke=2)+geom_point(data=onemax.icsoft[onemax.icsoft$VM == "deno",],pch=21, size=4, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
@
% 

The charts presented in Figure \ref{fig:onemax} show that there is indeed a variation for all three virtual machines, how they vary along every one of them is different. In the case of node.js, newer VMs take more or less the same time, but the consumption of energy is much less; since \cite{energy:js} showed that this is, indeed, one of the choke points of this VM, it makes it more interesting in low-consumption environment. The case of {\sf bun} is more complicated: performance is the same, but energy consumption seems to be lowered only for smaller chromosome sizes, getting an increase in size 4096. The case of {\sf deno} is even more complicated: there is change towards higher performance (experiments taking less time), which more or less correspond to the decrease in consumption. However, the strange behavior of this VM regarding chromosome size (already observed in \cite{energy:js}) will have to be checked further.


<<r crossoverx, echo=F, fig.show="hold", out.width="30%", fig.cap="Consumption and time for the crossover operator in the three different VMs; node left, bun center, deno right.\\protect\\label{fig:crossover}">>=
crossover.icsoft <- read.csv("../code/data/pinpoint-vms-crossover-11-Apr-17-06-52.csv")
crossover.icsoft$size <- as.factor(crossover.icsoft$size)
crossover.icsoft$VM <- str_trim(crossover.icsoft$VM)
crossover <- read.csv("../code/data/pinpoint-vms-crossover-29-May-18-49-13.csv")
crossover$size <- as.factor(crossover$size)
crossover$VM <- str_trim(crossover$VM)
ggplot(crossover[crossover$VM == "node",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, stroke=2)+geom_point(data=crossover.icsoft[crossover.icsoft$VM == "node",],pch=21, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
ggplot(crossover[crossover$VM == "bun",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, stroke=2)+geom_point(data=crossover.icsoft[crossover.icsoft$VM == "bun",],pch=21, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
ggplot(crossover[crossover$VM == "deno",], aes(x=seconds,y=PKG, color="May",fill=size))+geom_point(pch=22, size=4, stroke=2)+geom_point(data=crossover.icsoft[crossover.icsoft$VM == "deno",],pch=21, size=4, stroke=2,aes(x=seconds,y=PKG,color="March",fill=size))+theme_tufte()
@

The scenario that is shown in Figure \ref{fig:crossover}, representing performance for crossover, has some similarities with the one shown in Figure \ref{fig:onemax}, showing again the strange performance correlations for the {\sf deno} VM. In the other two cases, there is no great difference, even it can be slightly worse, although the difference does not seem to be significant.

Since our interest is first to try and find the JavaScript VM that has the best energy profile, we will first compare the energy consumption of the ones available in March 2023, and published in \cite{js:energy}, and the ones available in May 2023, when this paper is being written. It does not seem like the slight disadvantage in energy consumption for this new version, in this specific operator, is enough to offset the savings obtained with the fitness function; let us not forget that fitness evaluation usually takes the bulk of the energy consumption and time. At any rate, the fact that unexpected variations in energy consumption may occur when versions change, and sometimes dramatic ones, is probably enough to warrant re-profiling of all workloads (evolutionary algorithms or otherwise) and another round of comparison of the performance and energy consumption for all three. This is what we will do next, using the newest published versions.

%
<<r onemax.vms, echo=F, fig.cap="Boxplot of PKG measurements OneMax problem and the three different virtual machines.\\protect\\label{fig:onemax:energy}">>=
ggplot(onemax, aes(x=size,y=PKG))+geom_boxplot(aes(fill=VM))+ylim(0, NA)+theme_tufte()
onemax$kwh <- onemax$PKG * 2.77778e-7
onemax$cost.Spain <- onemax$kwh * 20
@
%

%Rewrite
The figure shows the almost-flat growth of energy consumption for {\sf bun}.
How consumption grows for {\sf deno} is weird, since it takes less energy when
the chromosome is bigger (4096). Once again, {\sf node} is the bigger energy
guzzler, consuming up to 3 times more than {\sf deno} on average, and more than
6 times as much as {\sf bun}. We will see how this is reflected in monetary
terms, taking into account that the cost in Spain today is around 0.2€/kWh.
This cost, shown in table \ref{tab:onemax:cost}, reaches almost one-hundredth
of a euro for the most "expensive" VM, {\sf node}; that gives you an idea of
the kind of cost the algorithms have, and also how this cost decreases almost
an order of magnitude if {\sf bun} is used.

<<r onemax.cost, echo=F, message=F>>=
library(dplyr)
onemax.cost <- onemax %>% group_by( size, VM) %>% summarise( average = mean( cost.Spain ), sd = sd( cost.Spain))
library(kableExtra)
kable(onemax.cost, caption="Estimated cost of the OneMax runs for every VM and size, in €-cents. \\protect\\label{tab:onemax:cost}")
@

The crossover operation involves copy operations between strings, as well as
creation of new strings. We will again generate 40K chromosomes and group them
in pairs; these strings will be crossed by interchanging a random
fragment from one to the other and back. The resulting pairs will be stored in
an array, which is eventually printed. The result of every experiment
is shown in an energy vs. wallclock time chart in Figure \ref{fig:xover}.

<<r crossover, echo=F, fig.cap="PKG consumption, in Joules, vs. time in seconds, for the crossover and the three different virtual machines.\\protect\\label{fig:xover}">>=
crossover.icsoft <- read.csv("../code/data/pinpoint-vms-crossover-11-Apr-17-06-52.csv")
crossover.icsoft$size <- as.factor(crossover.icsoft$size)
crossover <- read.csv("../code/data/pinpoint-vms-crossover-29-May-18-49-13.csv")
crossover$size <- as.factor(crossover$size)
 ggplot(crossover, aes(x=seconds,y=PKG))+geom_point(size=3,aes(color=size,fill=size,shape=VM))+theme_tufte()
@

The scenario is remarkably similar to the one shown in Figure \ref{fig:onemax}.
In the two cases, {\sf bun} achieves the top performance and lowest energy
consumption, and {\sf node} is the worst. Average energy consumption is shown as a
boxplot in Figure \ref{fig:crossover:energy}.

%
<<r crossover.energy, echo=F, fig.cap="Boxplot of PKG measurements for the crossover operator and the three different virtual machines.\\protect\\label{fig:crossover:energy}">>=
ggplot(crossover, aes(x=size,y=PKG))+geom_boxplot(aes(fill=VM))+ylim(0, NA)+theme_tufte()
@
%

Here we can see again the surprising fact that {\sf deno} takes the same amount
of energy, on average, as {\sf node} for size 2048, in a similar case to what
happened for OneMax (shown in Figure \ref{fig:onemax:energy}). The difference
between the thriftiest, {\sf bun}, and the heaviest consumer, {\sf node}, is
approximately three times, in this case, less than in the case of the OneMax fitness
function.

Given that the results for the two EA-specific functions,
as well as the test function, are quite conclusive, we should not expect
anything different from the mutation function, so we will leave the experiments
at these two, and proceed to the conclusions.

\section{Conclusions}
\label{sec:conc}


As we have indicated in the experimental session, the wide advantage that {\sf
bun} has over the other interpreters does not leave much room for adopting
different benchmarks that could make that ranking vary; at any rate, these
experiments have shown how much faster and energy-saving {\sf bun} is (from 1/3
to 1/6 the energy consumed by {\sf node}), but it would be interesting to know
what happens to this gap under different operations like selection or different
kind of mutation. At the same time, even if EAs are mostly
GPU-free, there are some fitness functions that operate on floating point
numbers and thus would need to use the GPU; how interpreters work in this area
could be an interesting future line of work. This, along with testing different
versions of the interpreters as they are published, will be the subject of
future research.


\section*{Acknowledgements}

This work is supported by the Ministerio espa\~{n}ol de Econom\'{\i}a y
Competitividad (Spanish Ministry of Competitivity and Economy) under project
PID2020-115570GB-C22 (DemocratAI::UGR).


\bibliographystyle{splncs04}

\bibliography{energy,javascript,geneura}


\end{document}

